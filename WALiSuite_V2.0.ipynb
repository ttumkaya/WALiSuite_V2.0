{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl in the directory, load data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The InLight col we have in the count csv files and count tab in the tdms file is based on cX data. Meaning that we're doing\n",
    "## head tracking but not using in the PI calculation.\n",
    "## Here, I wrote a function to generate InLight column for a given HeadX coordinates and respective borders.\n",
    "## I send only the headX while light ON (pattern01 or pattern10) to this function and return a binary list.\n",
    "def InLightDetection(data,minimumBorder,maximumBorder):\n",
    "    InLightBasedOnHeadXcoords = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if minimumBorder <= data[i] <= maximumBorder:\n",
    "            InLightBasedOnHeadXcoords.append(1)\n",
    "            \n",
    "        else:\n",
    "            InLightBasedOnHeadXcoords.append(0)\n",
    "    return InLightBasedOnHeadXcoords\n",
    "\n",
    "## Since the FPS from different cameras can be different, here I detect the FPS automatically rather than relying on user input.\n",
    "def detectFPS(timeStamps):\n",
    "    Second_prev = 0\n",
    "    counter = 0 \n",
    "    fpsDict= {}\n",
    "\n",
    "    for i in range(len(timeStamps)):\n",
    "        Second_next = timeStamps[i].second\n",
    "\n",
    "        if Second_next == Second_prev:\n",
    "            counter += 1 \n",
    "\n",
    "        else:\n",
    "            fpsDict[Second_prev] = counter\n",
    "            counter = 0\n",
    "\n",
    "        Second_prev = Second_next\n",
    "\n",
    "    fps = Counter(fpsDict.values()).most_common()[0][0]\n",
    "    \n",
    "    return fps\n",
    "\n",
    "def dataToDataframe(rootDir):\n",
    "        \n",
    "    ## Generate a single dataframe from the .tdms and pattern files \n",
    "    temp = {'Tdms file name':[],'Date':[],'Time':[],'mmPerPix':[],'fps':[],'Light Intensity(uW/mm2)':[],'Light Type':[],'Wind status':[],\n",
    "            'Satiety':[],'Genotype':[],'Sex':[],'Status':[],'Fly ID':[],'cX(pix)':[],'HeadX(pix)':[],'HeadX(pix)_smoothed':[],\n",
    "            'HeadY(pix)':[], 'InLight':[],'InLight_HeadX|P01':[],'InLight_HeadX|P10':[],'First light contact index_of_the_whole_data|P01':[],'First light contact index_of_the_whole_data|P10':[],\n",
    "            'LightON index|P01':[],'First light contact index in P01':[],'First light contact index in P10':[],'LightON index|P10':[],'Border|P01':[],'Border|P10':[]}\n",
    "    \n",
    "    # Removed 'Light type':[], since all constant\n",
    "    \n",
    "    slidingWindowSizeinframes = 25\n",
    "    numOfTdmsFiles = 0\n",
    "    ## get access to the files in each ORN folder\n",
    "    fileList = os.listdir(rootDir)\n",
    "    bar = progressbar.ProgressBar()       \n",
    "    ## Loop thru the file list to find tdms files and their related csv pattern files\n",
    "    for fname in bar(fileList):\n",
    "        if fname[-5:] == '.tdms':    \n",
    "            numOfTdmsFiles += 1\n",
    "            ## Open the tdms file\n",
    "            f = TdmsFile(os.path.join(rootDir,fname))\n",
    "            \n",
    "            ## Load the tdms into a pandas df\n",
    "            TDMSdf = f.as_dataframe()\n",
    "\n",
    "            try:\n",
    "            ## Open the pattern csv files to extract light border info per fly\n",
    "                tdmsNameNoExtension = fname[:-5]\n",
    "                P01_fname = tdmsNameNoExtension + '_Pattern01.csv'\n",
    "                P10_fname = tdmsNameNoExtension + '_Pattern10.csv'\n",
    "                \n",
    "                P01_df = pd.read_csv(os.path.join(rootDir,P01_fname))\n",
    "                P10_df = pd.read_csv(os.path.join(rootDir,P10_fname))\n",
    "                \n",
    "            except:\n",
    "                print 'No pattern file(s) for %s' %(tdmsNameNoExtension)\n",
    "                \n",
    "            ## Get exp info from the tdms filename\n",
    "            tdmsNameNoExtension = tdmsNameNoExtension.split('_')\n",
    "#             print tdmsNameNoExtension\n",
    "            date = tdmsNameNoExtension[1]\n",
    "            time = tdmsNameNoExtension[2]\n",
    "            genotype = tdmsNameNoExtension[3][3:]\n",
    "            sex = \"male\"\n",
    "            \n",
    "            ## This is an extra step for hypenated file names\n",
    "            tdmsNameNoExtension_byhypen = tdmsNameNoExtension[4].split('-')\n",
    "#             print tdmsNameNoExtension_byhypen\n",
    "            intensity = tdmsNameNoExtension_byhypen[0][3:]\n",
    "            lightType = tdmsNameNoExtension_byhypen[1]\n",
    "            windState = tdmsNameNoExtension_byhypen[2]\n",
    "            \n",
    "#             intensity = tdmsNameNoExtension[4][3:]\n",
    "#             lightType = tdmsNameNoExtension[5]\n",
    "#             windState = tdmsNameNoExtension[6]\n",
    "            satiety = \"fileName\"\n",
    "\n",
    "            ## Get the mm per pixel coefficient\n",
    "            metaData = f.object().properties\n",
    "            mmPerPix = metaData['X_mm_per_pixel']\n",
    "\n",
    "            ## Detect the fps of the data for the LXS metric\n",
    "\n",
    "            timeStamps = pd.to_datetime(TDMSdf[\"/\\'Count\\'/\\'Time'\"])\n",
    "            fps = detectFPS(timeStamps)\n",
    "\n",
    "            ## Get status info \n",
    "            if ('w1118' in genotype) | ('W1118' in genotype):\n",
    "                status = 'Parent'\n",
    "            elif (('Gal4' in genotype) | ('GAL4' in genotype)) & ('UAS' in genotype):\n",
    "                status = 'Offspring'\n",
    "            else:\n",
    "                status = 'Unknown'\n",
    "                print 'Unknown parental status in file %s' % (fname)\n",
    "\n",
    "            ## simply putting fly IDs as numbers does not work due to missing chambers (i.e 3,4,6,7)\n",
    "            ## thus, get a list of column names with fly IDs\n",
    "            listOfFlyIDs = TDMSdf.columns[TDMSdf.columns.str.contains(\"/'Tracker'/'HeadX_pix\")]\n",
    "\n",
    "            for fly in listOfFlyIDs:\n",
    "\n",
    "                ## get the fly ID from the data itself\n",
    "                flyIndex = int(fly[-4:-1])\n",
    "\n",
    "                ## format the fly index into 3 digits number,i.e '5' >> '005' \n",
    "                flyID = format(str(flyIndex).zfill(3))\n",
    "\n",
    "                ## generate column names for the data need to be pulled from the df\n",
    "                fly_cX_pix_ID = \"/\\'Count\\'/\\'Obj%s_cX'\" % flyIndex \n",
    "                fly_inLight_ID = \"/\\'Count\\'/\\'Obj%s_InLight'\" % flyIndex\n",
    "                fly_headX_pix_ID = \"/'Tracker'/'HeadX_pix\" + str(flyID) + \"'\"\n",
    "                fly_headY_pix_ID = \"/'Tracker'/'HeadY_pix\" + str(flyID) + \"'\"\n",
    "\n",
    "                temp['Fly ID'].append(flyID)\n",
    "                temp['cX(pix)'].append(TDMSdf[fly_cX_pix_ID].values.astype(float))\n",
    "                temp['InLight'].append(TDMSdf[fly_inLight_ID].values.astype(float))\n",
    "                temp['HeadX(pix)'].append(TDMSdf[fly_headX_pix_ID].values.astype(float))\n",
    "                temp['HeadX(pix)_smoothed'].append(pd.rolling_mean(TDMSdf[fly_headX_pix_ID].values.astype(float),\n",
    "                                                   window = slidingWindowSizeinframes, center=True, win_type=\"triang\"))\n",
    "                temp['HeadY(pix)'].append(TDMSdf[fly_headY_pix_ID].values.astype(float))\n",
    "\n",
    "            ## Get the chunks where the light was ON   \n",
    "            TDMSdf_pat01 = TDMSdf[TDMSdf[\"/\\'Count\\'/\\'PatternState'\"] == 'Pattern 01']    \n",
    "            TDMSdf_pat10 = TDMSdf[TDMSdf[\"/\\'Count\\'/\\'PatternState'\"] == 'Pattern 10'] \n",
    "\n",
    "            LightOnP01 = min(TDMSdf_pat01.index),max(TDMSdf_pat01.index)\n",
    "            LightOnP10 = min(TDMSdf_pat10.index),max(TDMSdf_pat10.index)\n",
    "\n",
    "            for fly in listOfFlyIDs:\n",
    "                ## get the fly ID from the data itself\n",
    "                flyIndex = int(fly[-4:-1])\n",
    "\n",
    "                ## format the fly index into 3 digits number,i.e '5' >> '005' \n",
    "                flyID = format(str(flyIndex).zfill(3))\n",
    "\n",
    "                ## generate column names for the data need to be pulled from the df\n",
    "                fly_headX_pix_ID = \"/'Tracker'/'HeadX_pix\" + str(flyID) + \"'\"\n",
    "                border_P01 = P01_df.filter(regex='pix').iloc[1].values[flyIndex-1]\n",
    "                border_P10 = P10_df.filter(regex='pix').iloc[1].values[flyIndex-1]\n",
    "\n",
    "                ## get the headX coordinates of the fly where the light was ON - pattern01 or pattern10\n",
    "                headXcoord_P01 = TDMSdf_pat01[fly_headX_pix_ID].values.astype(float)\n",
    "                headXcoord_P10 = TDMSdf_pat10[fly_headX_pix_ID].values.astype(float)  \n",
    "\n",
    "                ## send this data to the function along with the respective border info to get a binary list,\n",
    "                ## indicating whether the fly was in the light or not.\n",
    "                ## 0 to 146 are min and max limits of the arena. STRICTLY DEPENDING ON YOUR CAMERA!\n",
    "                InLightBasedOnHeadX_P01 = InLightDetection(headXcoord_P01,border_P01,600)\n",
    "                InLightBasedOnHeadX_P10 = InLightDetection(headXcoord_P10,0,border_P10)\n",
    "\n",
    "                ## if the fly had ever been in the light, get the first time she did.\n",
    "                if 1 in InLightBasedOnHeadX_P01:\n",
    "                    P01_first_light_contact_index_of_the_whole_data = int(LightOnP01[0]) + int(InLightBasedOnHeadX_P01.index(1))\n",
    "                    P01_first_light_contact_index_in_the_event = int(InLightBasedOnHeadX_P01.index(1))\n",
    "                else:\n",
    "                    P01_first_light_contact_index_of_the_whole_data = None\n",
    "                    P01_first_light_contact_index_in_the_event = None\n",
    "\n",
    "                if 1 in InLightBasedOnHeadX_P10:\n",
    "                    P10_first_light_contact_index_of_the_whole_data = int(LightOnP10[0]) + int(InLightBasedOnHeadX_P10.index(1))\n",
    "                    P10_first_light_contact_index_in_the_event = int(InLightBasedOnHeadX_P10.index(1))\n",
    "                else:\n",
    "                    P10_first_light_contact_index_of_the_whole_data = None\n",
    "                    P10_first_light_contact_index_in_the_event = None\n",
    "\n",
    "                ## append the info to temp dict\n",
    "                temp['First light contact index_of_the_whole_data|P01'].append(P01_first_light_contact_index_of_the_whole_data)\n",
    "                temp['First light contact index_of_the_whole_data|P10'].append(P10_first_light_contact_index_of_the_whole_data)  \n",
    "                temp['First light contact index in P01'].append(P01_first_light_contact_index_in_the_event)\n",
    "                temp['First light contact index in P10'].append(P10_first_light_contact_index_in_the_event)\n",
    "                temp['Tdms file name'].append(fname)\n",
    "                temp['Date'].append(date)\n",
    "                temp['Time'].append(time)\n",
    "                temp['mmPerPix'].append(mmPerPix)\n",
    "                temp['fps'].append(fps)\n",
    "                temp['Light Type'].append(lightType)\n",
    "                temp['Light Intensity(uW/mm2)'].append(intensity)\n",
    "                temp['Wind status'].append(windState)\n",
    "                temp['Satiety'].append(satiety)\n",
    "                temp['Genotype'].append(genotype)\n",
    "                temp['Sex'].append(sex)\n",
    "                temp['Status'].append(status)\n",
    "                temp['LightON index|P01'].append(LightOnP01)\n",
    "                temp['LightON index|P10'].append(LightOnP10)\n",
    "                temp['Border|P01'].append(border_P01)\n",
    "                temp['Border|P10'].append(border_P10)\n",
    "                temp['InLight_HeadX|P01'].append(InLightBasedOnHeadX_P01)\n",
    "                temp['InLight_HeadX|P10'].append(InLightBasedOnHeadX_P10)\n",
    "\n",
    "    ## Convert temp into a df\n",
    "    colOrder = ['Tdms file name','Date','Time','mmPerPix','fps','Light Intensity(uW/mm2)','Light Type','Wind status',\n",
    "                'Satiety','Genotype','Sex','Status','Fly ID','cX(pix)','HeadX(pix)','HeadX(pix)_smoothed','HeadY(pix)',\n",
    "                'InLight','InLight_HeadX|P01','InLight_HeadX|P10','First light contact index_of_the_whole_data|P01','First light contact index_of_the_whole_data|P10',\n",
    "                'LightON index|P01','First light contact index in P01','First light contact index in P10','LightON index|P10','Border|P01','Border|P10']\n",
    "\n",
    "    results = pd.DataFrame(temp,columns=colOrder)\n",
    "    results.to_pickle(rootDir + '/RawDataFrame.pkl')\n",
    "    ## summary of the raw data\n",
    "    summaryTable = results.groupby(['Genotype','Sex','Satiety','Wind status','Light Intensity(uW/mm2)']).size().reset_index(name='counts')\n",
    "    summaryTable.to_csv(rootDir + '/SummaryTableofTheRawData.csv')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: LaXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Usual PI calculation, called by\n",
    "def calculatePI(data):\n",
    "    \n",
    "    numofTimePoints = len(data)\n",
    "    totalTimeinLight = sum(data)\n",
    "    totalTimeinDark = numofTimePoints - totalTimeinLight\n",
    "    \n",
    "    PI = float(totalTimeinLight - totalTimeinDark)/float(numofTimePoints)\n",
    "    return PI\n",
    "\n",
    "def LaXS(df, rootDir,mergeIntensities, combineControls, Xsec = 30, dropNans = False):\n",
    "    numberOfFlies = df.shape[0]\n",
    "    LXS_P01_list = []\n",
    "    LXS_P10_list = []\n",
    "    \n",
    "    ## calculate LXS PI for each fly/row, and epoch (P01 | P10)\n",
    "    for fly in range(0,numberOfFlies):\n",
    "        \n",
    "        ## detect how many frames need to take from the tail\n",
    "        numberOfFrames = Xsec * int(df['fps'][fly])\n",
    "        \n",
    "        ## get the \"in light or not\" list per epoch\n",
    "        inLight_headX_P01 = df['InLight_HeadX|P01'][fly][-1*numberOfFrames:]\n",
    "        inLight_headX_P10 = df['InLight_HeadX|P10'][fly][-1*numberOfFrames:]\n",
    "        \n",
    "        ## send them to the calculate PI function\n",
    "        LXS_P01 = calculatePI(inLight_headX_P01)\n",
    "        LXS_P10 = calculatePI(inLight_headX_P10)\n",
    "        \n",
    "        ## store the PIs in lists\n",
    "        LXS_P01_list.append(LXS_P01)\n",
    "        LXS_P10_list.append(LXS_P10)\n",
    "    \n",
    "    ## add the new lists of information to the existing df\n",
    "    df = df.assign(LaXS_P01 = pd.Series(LXS_P01_list, index=df.index),\n",
    "                   LaXS_P10 = pd.Series(LXS_P10_list, index=df.index))\n",
    "    \n",
    "    df = df.assign(LaXS_Mean = pd.Series(df[['LaXS_P01','LaXS_P10']].mean(axis=1), \n",
    "                                                    index=df.index))\n",
    "    \n",
    "    plotTheMetric(df,'LaXS',rootDir,mergeIntensities, combineControls)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: TSALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TSALE(df, rootDir,mergeIntensities, combineControls=False, dropNans=False):\n",
    "    numberOfFlies = df.shape[0]\n",
    "    PI_afterLightContact_P01 = []\n",
    "    PI_afterLightContact_P10 = []\n",
    "    \n",
    "    ## iterate thru the flies to calculate PI scores\n",
    "    ## PI scores are calculated seperately for first and second halves of the experiment\n",
    "    for fly in range(0,numberOfFlies):\n",
    "        \n",
    "        ## get the first light contact index for the fly\n",
    "        firstLightContactIndex_P01 = df['First light contact index in P01'][fly]\n",
    "        firstLightContactIndex_P10 = df['First light contact index in P10'][fly]\n",
    "        \n",
    "        ## if the light contact index is NOT nan, calculate the PI and attach it to the list\n",
    "        ## otherwise attach a np.nan value\n",
    "        if not pd.isnull(firstLightContactIndex_P01):\n",
    "            \n",
    "            ## select the data after fly was exposed to the light\n",
    "            InLightDatainTheRange_P01 = df['InLight_HeadX|P01'][fly][int(firstLightContactIndex_P01):]\n",
    "            ## calculate PI score\n",
    "            numOfDataPoints_P01 = len(InLightDatainTheRange_P01)\n",
    "            numOfInLights_P01 = sum(InLightDatainTheRange_P01)\n",
    "            numOfInDarks_P01 = numOfDataPoints_P01 - numOfInLights_P01\n",
    "           \n",
    "            PI_P01 = float(numOfInLights_P01 - numOfInDarks_P01)/float(numOfDataPoints_P01)\n",
    "            PI_afterLightContact_P01.append(PI_P01)\n",
    "        \n",
    "        elif pd.isnull(firstLightContactIndex_P01):\n",
    "            PI_afterLightContact_P01.append(np.nan)\n",
    "        \n",
    "        else:\n",
    "            None\n",
    "        \n",
    "        ## same as the first half of the exp: P01\n",
    "        if not pd.isnull(firstLightContactIndex_P10):\n",
    "            \n",
    "            InLightDatainTheRange_P10 = df['InLight_HeadX|P10'][fly][int(firstLightContactIndex_P10):]\n",
    "            numOfDataPoints_P10 = len(InLightDatainTheRange_P10)\n",
    "            numOfInLights_P10 = sum(InLightDatainTheRange_P10)\n",
    "            numOfInDarks_P10 = numOfDataPoints_P10 - numOfInLights_P10\n",
    "            \n",
    "            PI_P10 = float(numOfInLights_P10 - numOfInDarks_P10)/float(numOfDataPoints_P10)\n",
    "            PI_afterLightContact_P10.append(PI_P10)\n",
    "        \n",
    "        elif pd.isnull(firstLightContactIndex_P10):\n",
    "            PI_afterLightContact_P10.append(np.nan)\n",
    "        \n",
    "        else:\n",
    "            None\n",
    "        \n",
    "        ## add the Preference Index pattern01 and pattern10 to the df\n",
    "    df = df.assign(TSALE_P01 = pd.Series(PI_afterLightContact_P01, index=df.index),\n",
    "                   TSALE_P10 = pd.Series(PI_afterLightContact_P10, index=df.index))\n",
    "    \n",
    "    df = df.assign(TSALE_Mean = pd.Series(df[['TSALE_P01','TSALE_P10']].mean(axis=1), index=df.index))\n",
    "    \n",
    "    droppedNans = MeanPreferenceIndexNoNANs(df)\n",
    "    \n",
    "    if dropNans == True:\n",
    "        plotTheMetric(droppedNans,'TSALE',rootDir,mergeIntensities,combineControls,dropNans)\n",
    "        \n",
    "        return droppedNans\n",
    "    else:\n",
    "        plotTheMetric(df,'TSALE',rootDir,mergeIntensities, combineControls,dropNans)\n",
    "    \n",
    "    return df\n",
    "\n",
    "## Nans in the PreferenceIndex_P01 (and P10) columns are treated as not existing in the plotting;\n",
    "## therefore, when I am getting the mean of the two columns, I can't treat them as zeroes. \n",
    "## This function, first removes all the rows where either PreferenceIndex_P01 OR PreferenceIndex_P10 is Nan,\n",
    "## then calculates a PreferenceIndex_Mean column to the df.\n",
    "def MeanPreferenceIndexNoNANs(df):\n",
    "    \n",
    "    droppedNans = df.dropna(subset = ['TSALE_P10','TSALE_P01'])\n",
    "    droppedNans = droppedNans.assign(TSALE_Mean_noNan = pd.Series(droppedNans[['TSALE_P01','TSALE_P10']].mean(axis=1), index = droppedNans.index))\n",
    "    droppedNans = droppedNans.reset_index(drop=True)\n",
    "    \n",
    "    return droppedNans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: weighted-TSALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_TSALE(dff, rootDir,mergeIntensities, compareLightType, combineControls=False, dropNans=False):\n",
    "    \n",
    "    df = TSALE(dff, rootDir,mergeIntensities, combineControls, dropNans)\n",
    "    ## empty lists to store the weights for both epochs\n",
    "    weights_P01 = []\n",
    "    weights_P10 = []\n",
    "    numofflies = df.shape[0]\n",
    "    \n",
    "    ## calculate weights per fly\n",
    "    for i in range(numofflies):\n",
    "        numofFrames_P01 = len(df['InLight_HeadX|P01'][i])\n",
    "        firstContact_P01 = df['First light contact index in P01'][i]\n",
    "\n",
    "        if not pd.isnull(firstContact_P01):\n",
    "            ## weight is calculated as: remaining time after the discovery / whole epoch\n",
    "            w_P01 = (numofFrames_P01-firstContact_P01)/float(numofFrames_P01)\n",
    "            weights_P01.append(w_P01)\n",
    "        else:\n",
    "            weights_P01.append(np.nan) \n",
    "\n",
    "        numofFrames_P10 = len(df['InLight_HeadX|P10'][i])\n",
    "        firstContact_P10 = df['First light contact index in P10'][i]\n",
    "\n",
    "        if not pd.isnull(firstContact_P10):\n",
    "            ## weight is remaining time after the discovery / whole epoch\n",
    "            w_P10 = (numofFrames_P10-firstContact_P10)/float(numofFrames_P10)\n",
    "            weights_P10.append(w_P10)\n",
    "        else:\n",
    "            weights_P10.append(np.nan) \n",
    "\n",
    "    df = df.assign(weights_P01 = pd.Series(weights_P01, index=df.index),\n",
    "                   weights_P10 = pd.Series(weights_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(weighted_TSALE_P01 = pd.Series(df['weights_P01'] * df['TSALE_P01'], index=df.index),\n",
    "                   weighted_TSALE_P10 = pd.Series(df['weights_P10'] * df['TSALE_P10'], index=df.index))\n",
    "\n",
    "    df = df.assign(weighted_TSALE_Mean = pd.Series(df[['weighted_TSALE_P01','weighted_TSALE_P10']].mean(axis=1), index=df.index))\n",
    "    \n",
    "    plotTheMetric(df,'weighted_TSALE',rootDir,mergeIntensities,combineControls,compareLightType,dropNans)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Light attraction index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function 1: Detect choice zone entrance/exits indices, store them in the df\n",
    "## Pass the df to these functions:\n",
    "    ## Function 2: Sort and Plot the tracts as in Wilson paper _ this only needs the entrance indices\n",
    "    ## Function 2.5: To plot the mean trajactories as in the Wilson paper, need an alignment function. Choice zone borders vary.\n",
    "    ## Function 3: Calculate Attraction Index from the exits _ this needs the exit indice, as well as coordination to decide \n",
    "    ## whether traversel or reversal.\n",
    "\n",
    "    ###!!! Fix HeadX to smoothed headX\n",
    "def DetectEntraceandExitIndicesToTheChoiceZone(df, choiceZoneWidth_mm = 10, thresholdToExcludeCursorJumps_pix = 20):\n",
    "\n",
    "    ## Lists to store the entrance and corresponding exits info per fly for P01 and P10\n",
    "    FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = []\n",
    "    FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = []\n",
    "\n",
    "    FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = []\n",
    "    FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = []\n",
    "    \n",
    "    ## Lists to stores choice zone borders per fly\n",
    "    ChoiceZoneBordersPerFly_P01 = []\n",
    "    ChoiceZoneBordersPerFly_P10 = []\n",
    "    \n",
    "    numberOfFlies = df.shape[0]\n",
    "\n",
    "    ## get the mm to pix coefficient\n",
    "    mmPerPix = df['mmPerPix'][0]\n",
    "\n",
    "    ## convert the zone width from mm to pix\n",
    "    choiceZoneWidth_pix = choiceZoneWidth_mm/mmPerPix\n",
    "\n",
    "    for fly in range(0,numberOfFlies):\n",
    "\n",
    "        ## one fly can have multiple decisions; I will keep seperate lists per fly\n",
    "        flyDecisionList_theWindPortEnd_P01 = []\n",
    "        flyDecisionList_theClosedEnd_P01 = []\n",
    "\n",
    "        flyDecisionList_theWindPortEnd_P10 = []\n",
    "        flyDecisionList_theClosedEnd_P10 = []\n",
    "\n",
    "        ## get border coordinates for the two light events per fly\n",
    "        border_P01 = df.iloc[fly]['Border|P01']\n",
    "        border_P10 = df.iloc[fly]['Border|P10'] \n",
    "\n",
    "        ## identify the choice zone lef-right borders per chamber, since borders change across chambers, even P01 vs P10 \n",
    "        choiceZoneBorders_P01 = [border_P01-choiceZoneWidth_pix/2, border_P01+choiceZoneWidth_pix/2]\n",
    "        choiceZoneBorders_P10 = [border_P10-choiceZoneWidth_pix/2, border_P10+choiceZoneWidth_pix/2]\n",
    "        \n",
    "        ## store the border info to be attached to the df\n",
    "        ChoiceZoneBordersPerFly_P01.append(choiceZoneBorders_P01)\n",
    "        ChoiceZoneBordersPerFly_P10.append(choiceZoneBorders_P10)\n",
    "        ## NTS: In Adam's paper, only when flies enter and exit counted as a decision.\n",
    "\n",
    "        ## get the indices where P01 and P10 were taking place      \n",
    "        P01_startIndex, P01_endIndex = df.iloc[fly]['LightON index|P01']\n",
    "        P10_startIndex, P10_endIndex = df.iloc[fly]['LightON index|P10']\n",
    "\n",
    "        ## get head X coordinates while the light was ON, P01 and P10\n",
    "        headXcoordIn_P01 = df.iloc[fly]['HeadX(pix)_smoothed'][P01_startIndex:P01_endIndex]\n",
    "        headXcoordIn_P10 = df.iloc[fly]['HeadX(pix)_smoothed'][P10_startIndex:P10_endIndex]\n",
    "\n",
    "        ## go thru the head X coordinates during the P01 event to find entrances and related exits(if any)\n",
    "        for i in range(len(headXcoordIn_P01)-1): \n",
    "            \n",
    "            ## if entering to the zone from the wind port end\n",
    "            if (headXcoordIn_P01[i] < choiceZoneBorders_P01[0]) & ((headXcoordIn_P01[i+1] > choiceZoneBorders_P01[0]) & (headXcoordIn_P01[i+1] < choiceZoneBorders_P01[1])):\n",
    "               \n",
    "                ## store the entrance info [entrance index, entrance coor]\n",
    "                temp = [P01_startIndex+i+1, headXcoordIn_P01[i+1]]\n",
    "\n",
    "                ## now detect the exit of this entrance\n",
    "                for j in range(len(headXcoordIn_P01[i:])-1):\n",
    "\n",
    "                    if (headXcoordIn_P01[i:][j+1] < choiceZoneBorders_P01[0]) | (headXcoordIn_P01[i:][j+1] > choiceZoneBorders_P01[1]):\n",
    "\n",
    "                        ## attach the exit to the temp list [entrance index, entrance coor, exit index, exit coor]\n",
    "                        temp.append(P01_startIndex+i+j+1)\n",
    "                        temp.append(headXcoordIn_P01[i+j+1])\n",
    "                        break\n",
    "\n",
    "                flyDecisionList_theWindPortEnd_P01.append(temp)\n",
    "                \n",
    "            ## found an entrance from the closed end of the chamber\n",
    "            if (headXcoordIn_P01[i] > choiceZoneBorders_P01[1]) & ((headXcoordIn_P01[i+1] < choiceZoneBorders_P01[1]) & (headXcoordIn_P01[i+1] > choiceZoneBorders_P01[0])):\n",
    "\n",
    "                ## store the entrance info [entrance index, entrance coor]\n",
    "                temp = [P01_startIndex+i+1, headXcoordIn_P01[i+1]]\n",
    "\n",
    "                ## now detect the exit of this entrance, if any\n",
    "                for j in range(len(headXcoordIn_P01[i:])-1):\n",
    "\n",
    "                    if (headXcoordIn_P01[i:][j+1] < choiceZoneBorders_P01[0]) | (headXcoordIn_P01[i:][j+1] > choiceZoneBorders_P01[1]):\n",
    "\n",
    "                        ## attach the exit to the temp list [entrance index, entrance coor, exit index, exit coor]\n",
    "                        temp.append(P01_startIndex+i+j+1)\n",
    "                        temp.append(headXcoordIn_P01[i+j+1])\n",
    "                        break\n",
    "                        \n",
    "                ## add this decision to the list before searching for other decisions of the same fly \n",
    "                flyDecisionList_theClosedEnd_P01.append(temp)\n",
    "        \n",
    "        \n",
    "        ## go thru the head X coordinates during the P10 event to find entrances and related exits(if any)\n",
    "        for i in range(len(headXcoordIn_P10)-1): \n",
    "            \n",
    "            ## if entering to the zone from the wind port end\n",
    "            if (headXcoordIn_P10[i] < choiceZoneBorders_P10[0]) & ((headXcoordIn_P10[i+1] > choiceZoneBorders_P10[0]) & (headXcoordIn_P10[i+1] < choiceZoneBorders_P10[1])):\n",
    "                \n",
    "                ## store the entrance info [entrance index, entrance coor]\n",
    "                temp = [P10_startIndex+i+1, headXcoordIn_P10[i+1]]\n",
    "                \n",
    "                ## now detect the exit of this entrance\n",
    "                for j in range(len(headXcoordIn_P10[i:])-1):\n",
    "\n",
    "                    if (headXcoordIn_P10[i:][j+1] < choiceZoneBorders_P10[0]) | (headXcoordIn_P10[i:][j+1] > choiceZoneBorders_P10[1]):\n",
    "\n",
    "                        ## attach the exit to the temp list [entrance index, entrance coor, exit index, exit coor]\n",
    "                        temp.append(P10_startIndex+i+j+1)\n",
    "                        temp.append(headXcoordIn_P10[i+j+1])\n",
    "                        break\n",
    "\n",
    "                flyDecisionList_theWindPortEnd_P10.append(temp)\n",
    "                \n",
    "            ## found an entrance from the closed end of the chamber\n",
    "            if (headXcoordIn_P10[i] > choiceZoneBorders_P10[1]) & ((headXcoordIn_P10[i+1] < choiceZoneBorders_P10[1]) & (headXcoordIn_P10[i+1] > choiceZoneBorders_P10[0])):\n",
    "\n",
    "                ## store the entrance info [entrance index, entrance coor]\n",
    "                temp = [P10_startIndex+i+1, headXcoordIn_P10[i+1]]\n",
    "\n",
    "                ## now detect the exit of this entrance, if any\n",
    "                for j in range(len(headXcoordIn_P10[i:])-1):\n",
    "\n",
    "                    if (headXcoordIn_P10[i:][j+1] < choiceZoneBorders_P10[0]) | (headXcoordIn_P10[i:][j+1] > choiceZoneBorders_P10[1]):\n",
    "\n",
    "                        ## attach the exit to the temp lis, [entrance index, entrance coor, exit index, exit coor]\n",
    "                        temp.append(P10_startIndex+i+j+1)\n",
    "                        temp.append(headXcoordIn_P10[i+j+1])\n",
    "                        break\n",
    "                        \n",
    "                ## add this decision to the list before searching for other decisions of the same fly \n",
    "                flyDecisionList_theClosedEnd_P10.append(temp)\n",
    "\n",
    "        FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX.append(flyDecisionList_theWindPortEnd_P01)\n",
    "        FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX.append(flyDecisionList_theClosedEnd_P01)\n",
    "\n",
    "        FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX.append(flyDecisionList_theWindPortEnd_P10)\n",
    "        FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX.append(flyDecisionList_theClosedEnd_P10)\n",
    "    \n",
    "    df = df.assign(ChoiceZoneBordersperFly_P01 = pd.Series(ChoiceZoneBordersPerFly_P01, index=df.index),\n",
    "                   ChoiceZoneBordersperFly_P10 = pd.Series(ChoiceZoneBordersPerFly_P10, index=df.index),\n",
    "                   FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = pd.Series(FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX, index=df.index),\n",
    "                   FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = pd.Series(FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX, index=df.index),\n",
    "                   FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = pd.Series(FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX, index=df.index),\n",
    "                   FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX = pd.Series(FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX, index=df.index))\n",
    "    return df\n",
    "\n",
    "def LAI(df, rootDir,mergeIntensities, combineControls=False, dropNans=False):\n",
    " \n",
    "    ## Caution: when you are calculating the LAI_Mean, getting the avarage of P01 and P10 may yield different results than\n",
    "    ## counting the votes for the two epochs.\n",
    "    ## P01 most probably will be excluded due to the conflicting of interpretations when the wind applied.\n",
    "    ## So, don't worry too much about the mean LAI.\n",
    "    ## LAI does not need to be calculated seperately for down and upwind cases. Combine them together.\n",
    "    ## The downwind/upwind will be nice to see in the path-analysis, and number of border crossings.\n",
    "    df = DetectEntraceandExitIndicesToTheChoiceZone(df)\n",
    "    \n",
    "    LightAttractionIndex_P01 = []\n",
    "    LightAttractionIndex_P10 = []\n",
    "\n",
    "    # go through all the flies\n",
    "    for fly in range(len(df)):\n",
    "\n",
    "        entrance_exit_log_P01 = []\n",
    "        entrance_exit_log_P10 = []\n",
    "\n",
    "        number_of_light_votes_P01 = 0\n",
    "        number_of_dark_votes_P01 = 0\n",
    "\n",
    "        number_of_light_votes_P10 = 0\n",
    "        number_of_dark_votes_P10 = 0\n",
    "        ## combine the choice events for P01 and P10, regardless to which part of the chamber flies entered to the zone\n",
    "        entrance_exit_log_P01.extend(df['FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "        entrance_exit_log_P01.extend(df['FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "\n",
    "        entrance_exit_log_P10.extend(df['FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "        entrance_exit_log_P10.extend(df['FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "\n",
    "        ## get the choice zone borders per fly to detect whether exit was to light or dark side\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "        ## go thru the entrances per fly and find out where the exits were made to\n",
    "        ## note that the light and dark sides are different sides of the border in each epoch\n",
    "        ## for P01\n",
    "        if entrance_exit_log_P01:\n",
    "            for log in entrance_exit_log_P01:\n",
    "                if len(log) == 4:\n",
    "                    exit_headX = log[3]\n",
    "                    \n",
    "                    ## NTS: using border line, instead of the choice zone borders, to compare the exit headX. Otherwise it\n",
    "                    ## fucks up.\n",
    "                    ##exit to the light side\n",
    "                    if exit_headX > border_P01:\n",
    "                        number_of_light_votes_P01 = number_of_light_votes_P01 + 1\n",
    "\n",
    "                    ##exit to the dark side    \n",
    "                    elif exit_headX < border_P01:\n",
    "                        number_of_dark_votes_P01 =  number_of_dark_votes_P01 + 1\n",
    "            \n",
    "            if (number_of_light_votes_P01 + number_of_dark_votes_P01) != 0:\n",
    "                LAI_P01 = (float(number_of_light_votes_P01) - float(number_of_dark_votes_P01))/(float(number_of_light_votes_P01) + float(number_of_dark_votes_P01))\n",
    "                LightAttractionIndex_P01.append(LAI_P01)\n",
    "            else:\n",
    "                LightAttractionIndex_P01.append(np.nan)\n",
    "        else:\n",
    "            LightAttractionIndex_P01.append(np.nan)\n",
    "            \n",
    "        ## for P10\n",
    "        if entrance_exit_log_P10:\n",
    "            for log in entrance_exit_log_P10:\n",
    "                if len(log) == 4:\n",
    "                    exit_headX = log[3]\n",
    "\n",
    "                    ##exit to the dark side\n",
    "                    if exit_headX > border_P10:\n",
    "                        number_of_dark_votes_P10 =  number_of_dark_votes_P10 + 1\n",
    "\n",
    "                    ##exit to the light side    \n",
    "                    elif exit_headX < border_P10:\n",
    "                        number_of_light_votes_P10 = number_of_light_votes_P10 + 1\n",
    "            if (number_of_light_votes_P10 + number_of_dark_votes_P10) != 0:\n",
    "                LAI_P10 = (float(number_of_light_votes_P10) - float(number_of_dark_votes_P10))/(float(number_of_light_votes_P10) + float(number_of_dark_votes_P10))\n",
    "                LightAttractionIndex_P10.append(LAI_P10)\n",
    "            else:\n",
    "                LightAttractionIndex_P10.append(np.nan)\n",
    "        else:\n",
    "            LightAttractionIndex_P10.append(np.nan) \n",
    "\n",
    "    df = df.assign(LAI_P01 = pd.Series(LightAttractionIndex_P01, index=df.index),\n",
    "                   LAI_P10 = pd.Series(LightAttractionIndex_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(LAI_Mean = pd.Series(df[['LAI_P01','LAI_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'LAI',rootDir,mergeIntensities,combineControls,dropNans)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrix: Reversal PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RPI(df, rootDir,mergeIntensities, combineControls=False, dropNans=False):\n",
    " \n",
    "    df = DetectEntraceandExitIndicesToTheChoiceZone(df)\n",
    "    \n",
    "    ReversalPI_P01 = []\n",
    "    ReversalPI_P10 = []\n",
    "    \n",
    "    # go through all the flies\n",
    "    for fly in range(len(df)):\n",
    "\n",
    "        entrance_exit_log_P01 = []\n",
    "        entrance_exit_log_P10 = []\n",
    "\n",
    "        number_of_light_reversals_P01 = 0\n",
    "        number_of_dark_reversals_P01 = 0\n",
    "\n",
    "        number_of_light_reversals_P10 = 0\n",
    "        number_of_dark_reversals_P10 = 0\n",
    "        \n",
    "        ## Use both the wind port and closed end entrances\n",
    "        entrance_exit_log_P01.extend(df['FromTheClosedEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "        entrance_exit_log_P01.extend(df['FromTheWindPortEnd_P01_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "\n",
    "        entrance_exit_log_P10.extend(df['FromTheClosedEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "        entrance_exit_log_P10.extend(df['FromTheWindPortEnd_P10_EnterIdx_EnterHeadX_ExitIdx_ExitHeadX'][fly])\n",
    "\n",
    "        ## get the border lines per fly to detect whether exit was to light or dark side\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "        \n",
    "        ## go thru the entrances per fly and find out where the exits were made to\n",
    "        ## note that the light and dark sides are different sides of the border in each epoch\n",
    "        ## for P01\n",
    "        if entrance_exit_log_P01:\n",
    "            for log in entrance_exit_log_P01:\n",
    "                if len(log) == 4:\n",
    "                    enter_headX = log[1]\n",
    "                    exit_headX = log[3]\n",
    "                    \n",
    "                    ##came from to the dark side, returned to the dark side\n",
    "                    if (enter_headX < border_P01) & (exit_headX < border_P01):\n",
    "                        number_of_dark_reversals_P01 = number_of_dark_reversals_P01 + 1\n",
    "\n",
    "                    ##came from the lit side, returned to the lit side   \n",
    "                    elif (enter_headX > border_P01) & (exit_headX > border_P01):\n",
    "                        number_of_light_reversals_P01 =  number_of_light_reversals_P01 + 1\n",
    "                        \n",
    "            if (number_of_dark_reversals_P01 + number_of_light_reversals_P01) != 0:\n",
    "                RPI_P01 = (float(number_of_light_reversals_P01) - float(number_of_dark_reversals_P01))/(float(number_of_light_reversals_P01) + float(number_of_dark_reversals_P01))\n",
    "                ReversalPI_P01.append(RPI_P01)\n",
    "                \n",
    "            else:\n",
    "                ReversalPI_P01.append(np.nan)\n",
    "        else:\n",
    "            ReversalPI_P01.append(np.nan)\n",
    "            \n",
    "        ## for P10\n",
    "        if entrance_exit_log_P10:\n",
    "            for log in entrance_exit_log_P10:\n",
    "                if len(log) == 4:\n",
    "                    enter_headX = log[1]\n",
    "                    exit_headX = log[3]\n",
    "\n",
    "                    ##came from light, returned to the lit side\n",
    "                    if (enter_headX < border_P10) & (exit_headX < border_P10):\n",
    "                        number_of_light_reversals_P10 =  number_of_light_reversals_P10 + 1\n",
    "\n",
    "                    ##came from the dark half, returned to the dark half   \n",
    "                    elif (enter_headX > border_P10) & (exit_headX > border_P10):\n",
    "                        number_of_dark_reversals_P10 = number_of_dark_reversals_P10 + 1\n",
    "                        \n",
    "            if (number_of_dark_reversals_P10 + number_of_light_reversals_P10) != 0:\n",
    "                RPI_P10 = (float(number_of_light_reversals_P10) - float(number_of_dark_reversals_P10))/(float(number_of_dark_reversals_P10) + float(number_of_light_reversals_P10))\n",
    "                ReversalPI_P10.append(RPI_P10)\n",
    "            else:\n",
    "                ReversalPI_P10.append(np.nan)\n",
    "        else:\n",
    "            ReversalPI_P10.append(np.nan) \n",
    "\n",
    "    df = df.assign(RPI_P01 = pd.Series(ReversalPI_P01, index=df.index),\n",
    "                   RPI_P10 = pd.Series(ReversalPI_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(RPI_Mean = pd.Series(df[['RPI_P01','RPI_P10']].mean(axis=1), index=df.index))\n",
    "    \n",
    "    plotTheMetric(df,'RPI',rootDir,mergeIntensities,combineControls,dropNans)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Number of Border Crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### NTS: fix this to SMOOTHED HEAD X!!\n",
    "def NoBC(df, rootDir, mergeIntensities,combineControls=False, dropNans=False):\n",
    "    \n",
    "    ## lists to keep the metric for each fly\n",
    "    list_of_number_of_border_crossings_P01 = []\n",
    "    list_of_number_of_border_crossings_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "\n",
    "        ## get the P01 and P10 epoch indices\n",
    "        start_of_P01 = df['LightON index|P01'][fly][0]\n",
    "        end_of_P01 = df['LightON index|P01'][fly][1]\n",
    "\n",
    "        start_of_P10 = df['LightON index|P10'][fly][0]\n",
    "        end_of_P10 = df['LightON index|P10'][fly][1]\n",
    "\n",
    "        ## get the head X positions during the epochs\n",
    "        headX_during_P01 = df['HeadX(pix)_smoothed'][fly][start_of_P01:end_of_P01]\n",
    "        headX_during_P10 = df['HeadX(pix)_smoothed'][fly][start_of_P10:end_of_P10]\n",
    "\n",
    "        ## get the border corrdinates\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "\n",
    "        ## values to keep the crossings for each fly\n",
    "        number_of_border_crossings_P01 = 0\n",
    "        number_of_border_crossings_P10 = 0\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## for P01 epoch\n",
    "        for i in range(len(headX_during_P01)-1):\n",
    "            current_coor = headX_during_P01[i]\n",
    "            next_coor = headX_during_P01[i+1]\n",
    "\n",
    "            if (current_coor > border_P01) & (next_coor < border_P01):\n",
    "                number_of_border_crossings_P01 = number_of_border_crossings_P01 + 1\n",
    "            elif (current_coor < border_P01) & (next_coor > border_P01):\n",
    "                number_of_border_crossings_P01 = number_of_border_crossings_P01 + 1\n",
    "        list_of_number_of_border_crossings_P01.append(number_of_border_crossings_P01)\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## for P10 epoch\n",
    "        for i in range(len(headX_during_P10)-1):\n",
    "            current_coor = headX_during_P10[i]\n",
    "            next_coor = headX_during_P10[i+1]\n",
    "\n",
    "            if (current_coor > border_P10) & (next_coor < border_P10):\n",
    "                number_of_border_crossings_P10 = number_of_border_crossings_P10 + 1\n",
    "                \n",
    "            elif (current_coor < border_P10) & (next_coor > border_P10):\n",
    "                number_of_border_crossings_P10 = number_of_border_crossings_P10 + 1\n",
    "\n",
    "        list_of_number_of_border_crossings_P10.append(number_of_border_crossings_P10)\n",
    "    \n",
    "    df = df.assign(NoBC_P01 = pd.Series(list_of_number_of_border_crossings_P01, index=df.index),\n",
    "                   NoBC_P10 = pd.Series(list_of_number_of_border_crossings_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(NoBC_Mean = pd.Series(df[['NoBC_P01','NoBC_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'NoBC',rootDir,mergeIntensities,combineControls,dropNans)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Speed ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### NTS: convert HeadX to SMOOTHED HEADX\n",
    "\n",
    "## 1. detect the chunks of headX that were in the epoch regions for before_the_light_P01, during_the_light_P01..\n",
    "## 2. calculate total distance travelled and total number of frames\n",
    "## 3. convert them into mm and sec\n",
    "## 4. calculate the ratio\n",
    "\n",
    "def calculateSpeed(data, fps, mmPerPixel):\n",
    "    \n",
    "    number_of_frames = 0\n",
    "    total_distance_pixel = 0\n",
    "    \n",
    "    ## Go thru the chunks of contuniued headX coordinates\n",
    "    for sublist in data:\n",
    "        for distance in sublist:\n",
    "            total_distance_pixel = total_distance_pixel + distance\n",
    "            number_of_frames = number_of_frames + 1\n",
    "    \n",
    "    if (number_of_frames != 0) & (total_distance_pixel != 0):\n",
    "        total_time_sec = float(number_of_frames) / float(fps)\n",
    "        total_distance_mm = total_distance_pixel * mmPerPixel\n",
    "\n",
    "        speed_pix_per_frame = float(total_distance_pixel)/float(number_of_frames)\n",
    "        speed_mm_per_sec = float(total_distance_mm)/float(total_time_sec)\n",
    "\n",
    "    else:\n",
    "        speed_pix_per_frame = np.nan\n",
    "        speed_mm_per_sec = np.nan\n",
    "        \n",
    "    return speed_mm_per_sec\n",
    "\n",
    "def Log2SpeedRatio(df ,rootDir,mergeIntensities, combineControls=False, dropNans=False):\n",
    "    list_of_log2_speed_ratio_P01 = []\n",
    "    list_of_log2_speed_ratio_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "    \n",
    "        ## get the light ON indices to detect before and during light episodes in an experiment\n",
    "        lightON_P01 = df['LightON index|P01'][fly]\n",
    "        lightON_P10 = df['LightON index|P10'][fly] \n",
    "\n",
    "        ## get the borders\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P01'][fly]\n",
    "\n",
    "        ## get fps and mmPerPixel for speed calculation\n",
    "        fps = df['fps'][fly]\n",
    "        mmPerPixel = df['mmPerPix'][fly]\n",
    "        ## get the fly's headX for the entire exp\n",
    "        fly_headX_coords = df['HeadX(pix)_smoothed'][fly]\n",
    "\n",
    "        ##  chop up the headX into the episodes\n",
    "        before_the_light_P01_headX = fly_headX_coords[:lightON_P01[0]]\n",
    "        during_the_light_P01_headX = fly_headX_coords[lightON_P01[0]:lightON_P01[1]]\n",
    "\n",
    "        before_the_light_P10_headX = fly_headX_coords[lightON_P01[1]:lightON_P10[0]]\n",
    "        during_the_light_P10_headX = fly_headX_coords[lightON_P10[0]:lightON_P10[1]]\n",
    "\n",
    "        ## lists to keep the chunks (lists) of headX there were in the region that the light was going to be turned ON\n",
    "        before_the_light_P01_headX_in_the_region = []\n",
    "        during_the_light_P01_headX_in_the_region = []\n",
    "\n",
    "        before_the_light_P10_headX_in_the_region = []\n",
    "        during_the_light_P10_headX_in_the_region = []\n",
    "\n",
    "        ## keep the indices of headX where they are in the region of interest\n",
    "        ## for P01\n",
    "        before_the_light_P01_headX_temp = []\n",
    "        for i in range(len(before_the_light_P01_headX)):\n",
    "            if before_the_light_P01_headX[i] > border_P01:\n",
    "                before_the_light_P01_headX_temp.append(i)\n",
    "\n",
    "        during_the_light_P01_headX_temp = []\n",
    "        for i in range(len(during_the_light_P01_headX)):\n",
    "            if during_the_light_P01_headX[i] > border_P01:\n",
    "                during_the_light_P01_headX_temp.append(i)\n",
    "\n",
    "        ## for P10\n",
    "        before_the_light_P10_headX_temp = []\n",
    "        for i in range(len(before_the_light_P10_headX)):\n",
    "            if before_the_light_P10_headX[i] < border_P10:\n",
    "                before_the_light_P10_headX_temp.append(i)\n",
    "\n",
    "        during_the_light_P10_headX_temp = []\n",
    "        for i in range(len(during_the_light_P10_headX)):\n",
    "            if during_the_light_P10_headX[i] < border_P10:\n",
    "                during_the_light_P10_headX_temp.append(i)\n",
    "\n",
    "        ## chop up the indices' lists and find consecutives\n",
    "        for k, g in groupby(enumerate(before_the_light_P01_headX_temp), lambda (i,x):i-x):\n",
    "            sublist = map(itemgetter(1), g)\n",
    "            if len(sublist) > 1:\n",
    "                before_the_light_P01_headX_in_the_region.append(sublist)\n",
    "\n",
    "        for k, g in groupby(enumerate(during_the_light_P01_headX_temp), lambda (i,x):i-x):\n",
    "            sublist = map(itemgetter(1), g)\n",
    "            if len(sublist) > 1:\n",
    "                during_the_light_P01_headX_in_the_region.append(sublist)\n",
    "\n",
    "        for k, g in groupby(enumerate(before_the_light_P10_headX_temp), lambda (i,x):i-x):\n",
    "            sublist = map(itemgetter(1), g)\n",
    "            if len(sublist) > 1:\n",
    "                before_the_light_P10_headX_in_the_region.append(sublist)\n",
    "\n",
    "        for k, g in groupby(enumerate(during_the_light_P10_headX_temp), lambda (i,x):i-x):\n",
    "            sublist = map(itemgetter(1), g)\n",
    "            if len(sublist) > 1:\n",
    "                during_the_light_P10_headX_in_the_region.append(sublist)\n",
    "\n",
    "        ## By using the index lists, create distance travelled lists of lists.\n",
    "        ## For P01\n",
    "        before_the_light_P01_headX_in_the_region_distance_travelled = []\n",
    "\n",
    "        for l in before_the_light_P01_headX_in_the_region:\n",
    "            start_idx = l[0]\n",
    "            end_idx = l[-1]\n",
    "            temp = []\n",
    "\n",
    "            for i in range(start_idx,end_idx):\n",
    "                diff = abs(before_the_light_P01_headX[i+1] - before_the_light_P01_headX[i])\n",
    "                temp.append(diff)\n",
    "            before_the_light_P01_headX_in_the_region_distance_travelled.append(temp)\n",
    "\n",
    "        during_the_light_P01_headX_in_the_region_distance_travelled = []\n",
    "\n",
    "        for l in during_the_light_P01_headX_in_the_region:\n",
    "            start_idx = l[0]\n",
    "            end_idx = l[-1]\n",
    "            temp = []\n",
    "\n",
    "            for i in range(start_idx,end_idx):\n",
    "                diff = abs(during_the_light_P01_headX[i+1] - during_the_light_P01_headX[i])\n",
    "                temp.append(diff)\n",
    "            during_the_light_P01_headX_in_the_region_distance_travelled.append(temp)\n",
    "\n",
    "        ## for P10\n",
    "        before_the_light_P10_headX_in_the_region_distance_travelled = []\n",
    "\n",
    "        for l in before_the_light_P10_headX_in_the_region:\n",
    "            start_idx = l[0]\n",
    "            end_idx = l[-1]\n",
    "            temp = []\n",
    "\n",
    "            for i in range(start_idx,end_idx):\n",
    "                diff = abs(before_the_light_P10_headX[i+1] - before_the_light_P10_headX[i])\n",
    "                temp.append(diff)\n",
    "            before_the_light_P10_headX_in_the_region_distance_travelled.append(temp)\n",
    "\n",
    "        during_the_light_P10_headX_in_the_region_distance_travelled = []\n",
    "\n",
    "        for l in during_the_light_P10_headX_in_the_region:\n",
    "            start_idx = l[0]\n",
    "            end_idx = l[-1]\n",
    "            temp = []\n",
    "\n",
    "            for i in range(start_idx,end_idx):\n",
    "                diff = abs(during_the_light_P10_headX[i+1] - during_the_light_P10_headX[i])\n",
    "                temp.append(diff)\n",
    "            during_the_light_P10_headX_in_the_region_distance_travelled.append(temp)\n",
    "\n",
    "        ## Send the distance travelled lists to the calculateSpeed function to get an average speed (mm/sec)    \n",
    "        speed_before_the_light_P01_headX_in_the_region = calculateSpeed(before_the_light_P01_headX_in_the_region_distance_travelled, fps, mmPerPixel)\n",
    "        speed_during_the_light_P01_headX_in_the_region = calculateSpeed(during_the_light_P01_headX_in_the_region_distance_travelled, fps, mmPerPixel)\n",
    "\n",
    "        speed_before_the_light_P10_headX_in_the_region = calculateSpeed(before_the_light_P10_headX_in_the_region_distance_travelled, fps, mmPerPixel)\n",
    "        speed_during_the_light_P10_headX_in_the_region = calculateSpeed(during_the_light_P10_headX_in_the_region_distance_travelled, fps, mmPerPixel)\n",
    "\n",
    "        ## Calculate the speed ratios for P01 and P10\n",
    "        speed_ratio_P01 = speed_during_the_light_P01_headX_in_the_region / speed_before_the_light_P01_headX_in_the_region\n",
    "        speed_ratio_P10 = speed_during_the_light_P10_headX_in_the_region / speed_before_the_light_P10_headX_in_the_region\n",
    "\n",
    "        ## Get and Store the log2 of the ratios\n",
    "        log2_speed_ratio_P01 = math.log(speed_ratio_P01, 2.0)\n",
    "        log2_speed_ratio_P10 = math.log(speed_ratio_P10, 2.0)\n",
    "\n",
    "        list_of_log2_speed_ratio_P01.append(log2_speed_ratio_P01)\n",
    "        list_of_log2_speed_ratio_P10.append(log2_speed_ratio_P10)\n",
    "\n",
    "\n",
    "    df = df.assign(Log2SpeedRatio_P01 = pd.Series(list_of_log2_speed_ratio_P01, index=df.index),\n",
    "                   Log2SpeedRatio_P10 = pd.Series(list_of_log2_speed_ratio_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(Log2SpeedRatio_Mean = pd.Series(df[['Log2SpeedRatio_P01','Log2SpeedRatio_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'Log2SpeedRatio',rootDir,mergeIntensities,combineControls,dropNans)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Delta Time Spent Before and During Light"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculatePercentageTimeSpent(data, total_epoch_time):\n",
    "    \n",
    "    percentageTimeSpent = float(len(data)) / float(total_epoch_time) * 100\n",
    "    \n",
    "    return percentageTimeSpent\n",
    "\n",
    "def DeltaPercentTimeSpent(df, rootDir, mergeIntensities,combineControls=False, dropNans=False):\n",
    "    list_of_delta_per_time_spent_P01 = []\n",
    "    list_of_delta_per_time_spent_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "\n",
    "        ## get the light ON indices to detect before and during light episodes in an experiment\n",
    "        lightON_P01 = df['LightON index|P01'][fly]\n",
    "        lightON_P10 = df['LightON index|P10'][fly] \n",
    "\n",
    "        ## get the borders\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P01'][fly]\n",
    "\n",
    "        ## get the fly's headX for the entire exp\n",
    "        fly_headX_coords = df['HeadX(pix)_smoothed'][fly]\n",
    "\n",
    "        ##  chop up the headX into the episodes\n",
    "        before_the_light_P01_headX = fly_headX_coords[:lightON_P01[0]]\n",
    "        during_the_light_P01_headX = fly_headX_coords[lightON_P01[0]:lightON_P01[1]]\n",
    "\n",
    "        before_the_light_P10_headX = fly_headX_coords[lightON_P01[1]:lightON_P10[0]]\n",
    "        during_the_light_P10_headX = fly_headX_coords[lightON_P10[0]:lightON_P10[1]]\n",
    "\n",
    "        ## lists to keep the chunks (lists) of headX there were in the region that the light was going to be turned ON\n",
    "        before_the_light_P01_headX_in_the_region = []\n",
    "        during_the_light_P01_headX_in_the_region = []\n",
    "\n",
    "        before_the_light_P10_headX_in_the_region = []\n",
    "        during_the_light_P10_headX_in_the_region = []\n",
    "\n",
    "        ## keep the indices of headX where they are in the region of interest\n",
    "        ## for P01\n",
    "        before_the_light_P01_headX_temp = []\n",
    "        for i in range(len(before_the_light_P01_headX)):\n",
    "            if before_the_light_P01_headX[i] > border_P01:\n",
    "                before_the_light_P01_headX_temp.append(i)\n",
    "\n",
    "        during_the_light_P01_headX_temp = []\n",
    "        for i in range(len(during_the_light_P01_headX)):\n",
    "            if during_the_light_P01_headX[i] > border_P01:\n",
    "                during_the_light_P01_headX_temp.append(i)\n",
    "\n",
    "        ## for P10\n",
    "        before_the_light_P10_headX_temp = []\n",
    "        for i in range(len(before_the_light_P10_headX)):\n",
    "            if before_the_light_P10_headX[i] < border_P10:\n",
    "                before_the_light_P10_headX_temp.append(i)\n",
    "\n",
    "        during_the_light_P10_headX_temp = []\n",
    "        for i in range(len(during_the_light_P10_headX)):\n",
    "            if during_the_light_P10_headX[i] < border_P10:\n",
    "                during_the_light_P10_headX_temp.append(i)\n",
    "                \n",
    "        ## calculate the percentage of the time spent in the region of interest\n",
    "        before_the_light_P01_perTimeSpent = calculatePercentageTimeSpent(before_the_light_P01_headX_temp, len(before_the_light_P01_headX))\n",
    "        during_the_light_P01_perTimeSpent = calculatePercentageTimeSpent(during_the_light_P01_headX_temp, len(during_the_light_P01_headX))\n",
    "\n",
    "        before_the_light_P10_perTimeSpent = calculatePercentageTimeSpent(before_the_light_P10_headX_temp, len(before_the_light_P10_headX))\n",
    "        during_the_light_P10_perTimeSpent = calculatePercentageTimeSpent(during_the_light_P10_headX_temp, len(during_the_light_P10_headX))\n",
    "\n",
    "        ## get the difference between dark and light phases\n",
    "        deltaPerTimeSpent_P01 = during_the_light_P01_perTimeSpent - before_the_light_P01_perTimeSpent\n",
    "        deltaPerTimeSpent_P10 = during_the_light_P10_perTimeSpent - before_the_light_P10_perTimeSpent\n",
    "\n",
    "        list_of_delta_per_time_spent_P01.append(deltaPerTimeSpent_P01)\n",
    "        list_of_delta_per_time_spent_P10.append(deltaPerTimeSpent_P10)\n",
    "\n",
    "\n",
    "    df = df.assign(DeltaPercentTimeSpent_P01 = pd.Series(list_of_delta_per_time_spent_P01, index=df.index),\n",
    "                   DeltaPercentTimeSpent_P10 = pd.Series(list_of_delta_per_time_spent_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(DeltaPercentTimeSpent_Mean = pd.Series(df[['DeltaPercentTimeSpent_P01','DeltaPercentTimeSpent_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'DeltaPercentTimeSpent',rootDir,mergeIntensities,combineControls,dropNans)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Speed crossing inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateAcuteSpeed(data, crossing_idx, fps, mmPerPix, length_sec=3):\n",
    "    sec_to_frames = length_sec * fps\n",
    "    crossing_phase = data[crossing_idx:crossing_idx+sec_to_frames]\n",
    "    \n",
    "    total_distance_pix = np.sum(np.absolute(np.diff(crossing_phase)))\n",
    "    total_distance_mm = total_distance_pix * mmPerPix\n",
    "\n",
    "    acute_speed_pix_per_frame = float(total_distance_pix)/float(sec_to_frames)\n",
    "    acute_speed_mm_per_sec = float(total_distance_mm)/float(length_sec)\n",
    "    \n",
    "    return acute_speed_mm_per_sec\n",
    "\n",
    "def SpeedCrossingInside(df, rootDir,mergeIntensities, combineControls=False, dropNans=False):\n",
    "    ## lists to keep the metric for each fly\n",
    "    averaged_list_of_acute_speed_crossing_inside_P01 = []\n",
    "    averaged_list_of_acute_speed_crossing_inside_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "        ## lists to keep the metric for each fly\n",
    "        list_of_acute_speed_crossing_inside_P01 = []\n",
    "        list_of_acute_speed_crossing_inside_P10 = []\n",
    "\n",
    "        ## get the P01 and P10 epoch indices\n",
    "        start_of_P01 = df['LightON index|P01'][fly][0]\n",
    "        end_of_P01 = df['LightON index|P01'][fly][1]\n",
    "\n",
    "        start_of_P10 = df['LightON index|P10'][fly][0]\n",
    "        end_of_P10 = df['LightON index|P10'][fly][1]\n",
    "\n",
    "        ## get the head X positions during the epochs\n",
    "        headX_during_P01 = df['HeadX(pix)_smoothed'][fly][start_of_P01:end_of_P01]\n",
    "        headX_during_P10 = df['HeadX(pix)_smoothed'][fly][start_of_P10:end_of_P10]\n",
    "\n",
    "        ## get the border corrdinates\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "\n",
    "        ## get the fps for acute speed calculations\n",
    "        fps = df['fps'][fly]\n",
    "        mmPerPix = df['mmPerPix'][fly]\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## every time detect a cross, send the index to the calculateAcuteSpeed function\n",
    "        ## for P01 epoch\n",
    "        for i in range(len(headX_during_P01)-1):\n",
    "            current_coor = headX_during_P01[i]\n",
    "            next_coor = headX_during_P01[i+1]\n",
    "\n",
    "            ## only when crossing inside            \n",
    "            if (current_coor < border_P01) & (next_coor > border_P01):\n",
    "                acute_speed_change_crossing_inside_P01 = calculateAcuteSpeed(headX_during_P01, crossing_idx = i, fps = fps, mmPerPix = mmPerPix, length_sec = 3)\n",
    "                list_of_acute_speed_crossing_inside_P01.append(acute_speed_change_crossing_inside_P01)\n",
    "\n",
    "                ## Since each fly can have multiple border crossings and hence acute speeds,I get the average per fly.\n",
    "        if list_of_acute_speed_crossing_inside_P01 > 0:\n",
    "            average_acute_speed_change_P01 = np.mean(list_of_acute_speed_crossing_inside_P01)\n",
    "            averaged_list_of_acute_speed_crossing_inside_P01.append(average_acute_speed_change_P01)\n",
    "        else:\n",
    "            averaged_list_of_acute_speed_crossing_inside_P01.append(np.nan)\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## every time detect a cross, send the index to the calculateAcuteSpeed function\n",
    "        ## for P10 epoch\n",
    "        for i in range(len(headX_during_P10)-1):\n",
    "            current_coor = headX_during_P10[i]\n",
    "            next_coor = headX_during_P10[i+1]\n",
    "\n",
    "            ## only when crossing inside            \n",
    "            if (current_coor > border_P10) & (next_coor < border_P10):\n",
    "                acute_speed_change_crossing_inside_P10 = calculateAcuteSpeed(headX_during_P10, crossing_idx = i, fps = fps, mmPerPix = mmPerPix, length_sec = 3)\n",
    "                list_of_acute_speed_crossing_inside_P10.append(acute_speed_change_crossing_inside_P10)\n",
    "\n",
    "        ## Since each fly can have multiple border crossings and hence acute speeds,I get the average per fly.\n",
    "        if list_of_acute_speed_crossing_inside_P10 > 0:\n",
    "            average_acute_speed_change_P10 = np.mean(list_of_acute_speed_crossing_inside_P10)\n",
    "            averaged_list_of_acute_speed_crossing_inside_P10.append(average_acute_speed_change_P10)\n",
    "        else:\n",
    "            averaged_list_of_acute_speed_crossing_inside_P10.append(np.nan)\n",
    "\n",
    "\n",
    "    df = df.assign(SpeedCrossingInside_P01 = pd.Series(averaged_list_of_acute_speed_crossing_inside_P01, index=df.index),\n",
    "                   SpeedCrossingInside_P10 = pd.Series(averaged_list_of_acute_speed_crossing_inside_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(SpeedCrossingInside_Mean = pd.Series(df[['SpeedCrossingInside_P01','SpeedCrossingInside_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'SpeedCrossingInside',rootDir,mergeIntensities,combineControls,dropNans)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric: Speed crossing outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculateAcuteSpeed(data, crossing_idx, fps, mmPerPix, length_sec=3):\n",
    "    sec_to_frames = length_sec * fps\n",
    "    crossing_phase = data[crossing_idx:crossing_idx+sec_to_frames]\n",
    "    \n",
    "    total_distance_pix = np.sum(np.absolute(np.diff(crossing_phase)))\n",
    "    total_distance_mm = total_distance_pix * mmPerPix\n",
    "\n",
    "    acute_speed_pix_per_frame = float(total_distance_pix)/float(sec_to_frames)\n",
    "    acute_speed_mm_per_sec = float(total_distance_mm)/float(length_sec)\n",
    "    \n",
    "    return acute_speed_mm_per_sec\n",
    "\n",
    "def SpeedCrossingOutside(df, rootDir,mergeIntensities, combineControls=False, dropNans=False):\n",
    "    ## lists to keep the metric for each fly\n",
    "    averaged_list_of_acute_speed_crossing_outside_P01 = []\n",
    "    averaged_list_of_acute_speed_crossing_outside_P10 = []\n",
    "\n",
    "    for fly in range(len(df)):\n",
    "        ## lists to keep the metric for each fly\n",
    "        list_of_acute_speed_crossing_outside_P01 = []\n",
    "        list_of_acute_speed_crossing_outside_P10 = []\n",
    "\n",
    "        ## get the P01 and P10 epoch indices\n",
    "        start_of_P01 = df['LightON index|P01'][fly][0]\n",
    "        end_of_P01 = df['LightON index|P01'][fly][1]\n",
    "\n",
    "        start_of_P10 = df['LightON index|P10'][fly][0]\n",
    "        end_of_P10 = df['LightON index|P10'][fly][1]\n",
    "\n",
    "        ## get the head X positions during the epochs\n",
    "        headX_during_P01 = df['HeadX(pix)_smoothed'][fly][start_of_P01:end_of_P01]\n",
    "        headX_during_P10 = df['HeadX(pix)_smoothed'][fly][start_of_P10:end_of_P10]\n",
    "\n",
    "        ## get the border corrdinates\n",
    "        border_P01 = df['Border|P01'][fly]\n",
    "        border_P10 = df['Border|P10'][fly]\n",
    "\n",
    "        ## get the fps for acute speed calculations\n",
    "        fps = df['fps'][fly]\n",
    "        mmPerPix = df['mmPerPix'][fly]\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## every time detect a cross, send the index to the calculateAcuteSpeed function\n",
    "        ## for P01 epoch\n",
    "        for i in range(len(headX_during_P01)-1):\n",
    "            current_coor = headX_during_P01[i]\n",
    "            next_coor = headX_during_P01[i+1]\n",
    "\n",
    "            ## only when crossing outside            \n",
    "            if (current_coor > border_P01) & (next_coor < border_P01):\n",
    "                acute_speed_change_crossing_outside_P01 = calculateAcuteSpeed(headX_during_P01, crossing_idx = i, fps = fps, mmPerPix = mmPerPix, length_sec = 3)\n",
    "                list_of_acute_speed_crossing_outside_P01.append(acute_speed_change_crossing_outside_P01)\n",
    "\n",
    "        ## Since each fly can have multiple border crossings and hence acute speeds,I get the average per fly.\n",
    "        if list_of_acute_speed_crossing_outside_P01 > 0:\n",
    "            average_acute_speed_change_P01 = np.mean(list_of_acute_speed_crossing_outside_P01)\n",
    "            averaged_list_of_acute_speed_crossing_outside_P01.append(average_acute_speed_change_P01)\n",
    "        else:\n",
    "            averaged_list_of_acute_speed_crossing_outside_P01.append(np.nan)\n",
    "\n",
    "        ## go thru the headX coords and detect border crossings\n",
    "        ## every time detect a cross, send the index to the calculateAcuteSpeed function\n",
    "        ## for P10 epoch\n",
    "        for i in range(len(headX_during_P10)-1):\n",
    "            current_coor = headX_during_P10[i]\n",
    "            next_coor = headX_during_P10[i+1]\n",
    "\n",
    "            ## only when crossing outside            \n",
    "            if (current_coor < border_P10) & (next_coor > border_P10):\n",
    "                acute_speed_change_crossing_outside_P10 = calculateAcuteSpeed(headX_during_P10, crossing_idx = i, fps = fps, mmPerPix = mmPerPix, length_sec = 3)\n",
    "                list_of_acute_speed_crossing_outside_P10.append(acute_speed_change_crossing_outside_P10)\n",
    "\n",
    "        ## Since each fly can have multiple border crossings and hence acute speeds,I get the average per fly.\n",
    "        if list_of_acute_speed_crossing_outside_P10 > 0:\n",
    "            average_acute_speed_change_P10 = np.mean(list_of_acute_speed_crossing_outside_P10)\n",
    "            averaged_list_of_acute_speed_crossing_outside_P10.append(average_acute_speed_change_P10)\n",
    "        else:\n",
    "            averaged_list_of_acute_speed_crossing_outside_P10.append(np.nan)\n",
    "\n",
    "\n",
    "    df = df.assign(SpeedCrossingOutside_P01 = pd.Series(averaged_list_of_acute_speed_crossing_outside_P01, index=df.index),\n",
    "                   SpeedCrossingOutside_P10 = pd.Series(averaged_list_of_acute_speed_crossing_outside_P10, index=df.index))\n",
    "\n",
    "    df = df.assign(SpeedCrossingOutside_Mean = pd.Series(df[['SpeedCrossingOutside_P01','SpeedCrossingOutside_P10']].mean(axis=1), index=df.index))\n",
    "    plotTheMetric(df,'SpeedCrossingOutside',rootDir,mergeIntensities,combineControls,dropNans)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Queue\n",
    "\n",
    "### Stop probability\n",
    "### Velocity crossing in and out of the odor zone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plot a single fly's trajectory as well as first light contacts.\n",
    "def VisualizeSingleFlyTrajectory(df,flyiLoc,mark =False, smoothHeadX = False, speed= False):\n",
    "    singleFlyData = df.iloc[flyiLoc,:]\n",
    "\n",
    "    ## Get the data for the selected fly\n",
    "    genotype = singleFlyData['Genotype']\n",
    "    lightON_P01,lightOFF_P01 = singleFlyData['LightON index|P01'][0],singleFlyData['LightON index|P01'][1]\n",
    "    lightON_P10,lightOFF_P10 = singleFlyData['LightON index|P10'][0],singleFlyData['LightON index|P10'][1]\n",
    "    if (smoothHeadX == False):\n",
    "        headXData = singleFlyData['HeadX(pix)']\n",
    "    elif (smoothHeadX == True):\n",
    "        headXData = singleFlyData['HeadX(pix)_smoothed']\n",
    "    \n",
    "    ## If no contact with light, assign 0\n",
    "    firstLightContact_P01 = int(singleFlyData['First light contact index_of_the_whole_data|P01']) if math.isnan(singleFlyData['First light contact index_of_the_whole_data|P01']) == False else 0\n",
    "    firstLightContact_P10 = int(singleFlyData['First light contact index_of_the_whole_data|P10']) if math.isnan(singleFlyData['First light contact index_of_the_whole_data|P10']) == False else 0\n",
    "    border_P01 = singleFlyData['Border|P01']\n",
    "    border_P10 = singleFlyData['Border|P10']\n",
    "    ChoiceZoneBorders_P01 = singleFlyData['ChoiceZoneBordersperFly_P01']\n",
    "    ChoiceZoneBorders_P10 = singleFlyData['ChoiceZoneBordersperFly_P10']\n",
    "    \n",
    "    ## Open a new figure\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax1 = plt.subplot(111)\n",
    "\n",
    "    if speed == True:\n",
    "        speed = np.absolute(np.diff(headXData))\n",
    "        ax1.plot(range(len(speed)), speed, color='black')\n",
    "        \n",
    "        normalized_border_P01 = border_P01/145.0\n",
    "        normalized_border_P10 = border_P10/145.0\n",
    "        \n",
    "        ax1.axvspan(lightON_P01, lightOFF_P01, ymin = normalized_border_P01, ymax = 1, color='red', alpha=0.3)\n",
    "        ax1.axvspan(lightON_P10, lightOFF_P10, ymin = 0, ymax = normalized_border_P10, color='red', alpha=0.3)\n",
    "        ax1.set_ylabel('Absolute Speed')\n",
    "        ax1.set_xlabel('Time frames')\n",
    "    else:\n",
    "        ax1.plot(range(len(headXData)), headXData, color='black')\n",
    "\n",
    "        ## Normalize borders to a range between 0-1 for the axvspan function\n",
    "        normalized_border_P01 = border_P01/145.0\n",
    "        normalized_border_P10 = border_P10/145.0\n",
    "\n",
    "        ax1.axvspan(lightON_P01, lightOFF_P01, ymin = normalized_border_P01, ymax = 1, color='red', alpha=0.3)\n",
    "        ax1.axvspan(lightON_P10, lightOFF_P10, ymin = 0, ymax = normalized_border_P10, color='red', alpha=0.3)\n",
    "        if firstLightContact_P01 != 0:\n",
    "            ax1.annotate('first' +'\\n'+ 'contact', xy=(firstLightContact_P01, headXData[firstLightContact_P01]), \n",
    "                     xytext=(firstLightContact_P01,headXData[firstLightContact_P01]), arrowprops=dict(facecolor='royalblue', shrink=0.05,lw=0))\n",
    "\n",
    "        if firstLightContact_P10 != 0:\n",
    "            ax1.annotate('first' +'\\n'+ 'contact', xy=(firstLightContact_P10, headXData[firstLightContact_P10]), \n",
    "                     xytext=(firstLightContact_P10,headXData[firstLightContact_P10]), arrowprops=dict(facecolor='royalblue', shrink=0.05,lw=0))\n",
    "\n",
    "        ax1.axhline(y=ChoiceZoneBorders_P01[0],xmin=.195,xmax=.42,color='coral')        \n",
    "        ax1.axhline(y=ChoiceZoneBorders_P01[1],xmin=.195,xmax=.42,color='coral')\n",
    "        ax1.axhline(y=ChoiceZoneBorders_P10[0],xmin=.575,xmax=.80,color='coral')        \n",
    "        ax1.axhline(y=ChoiceZoneBorders_P10[1],xmin=.575,xmax=.80,color='coral')\n",
    "\n",
    "        if mark != False:\n",
    "            ax1.axvline(mark, color = 'blue')\n",
    "        ax1.set_ylim(0,146)\n",
    "        ax1.set_ylabel('HeadX (pix)')\n",
    "        ax1.set_xlabel('Time frames')\n",
    "        sns.set(style=\"ticks\", palette=\"bright\", color_codes=True)\n",
    "        sns.despine(trim=True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd = pd.read_pickle(\"T:\\\\ACC\\\\Tayfuntumkaya\\\\DATA\\\\CompleteWALiSARORNData_Analyzed\\Gr66a\\\\LAI\\\\LAI_values.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd.iloc[620]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flyiLoc = 640\n",
    "f = VisualizeSingleFlyTrajectory(dd, flyiLoc=flyiLoc, mark = False, smoothHeadX=True, speed=False)\n",
    "f\n",
    "plt.savefig(\"C:/Users/tumkayat/Desktop/Gr66a-Gal4_UAS-CsChrimson_640thFly.pdf\",dpi=1000,bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def VisualizeGroupsOfData(group,data,counter,numOfGroups,axs,individualFlies,durationAfterEntrance_frames,ylim):\n",
    "    \n",
    "    if individualFlies == None:\n",
    "        meanBorder_P01 = np.mean(np.asanyarray(data['Border|P01'].tolist()),axis=0)\n",
    "        meanBorder_P10 = np.mean(np.asanyarray(data['Border|P10'].tolist()),axis=0)\n",
    "        meanChoiceZoneBorders_P01 = np.mean(np.asanyarray(data['ChoiceZoneBordersperFly_P01'].tolist()),axis=0)\n",
    "        meanChoiceZoneBorders_P10 = np.mean(np.asanyarray(data['ChoiceZoneBordersperFly_P10'].tolist()),axis=0)\n",
    "        \n",
    "        #if mean == False:\n",
    "        for fly in range(len(data)):\n",
    "            singleFlyDf = data.iloc[fly]\n",
    "            singleFlyHeadX = singleFlyDf['HeadX(pix)']\n",
    "\n",
    "            singleFlyEntranceData_TheWindSide_P01 = singleFlyDf['FromTheWindPortEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheWindSide_P01 = [item[0] for item in singleFlyEntranceData_TheWindSide_P01 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheWindSide_P01:\n",
    "                axs[counter+0].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = .6, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheClosedSide_P01 = singleFlyDf['FromTheClosedEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheClosedSide_P01 = [item[0] for item in singleFlyEntranceData_TheClosedSide_P01 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheClosedSide_P01:\n",
    "                axs[counter+numOfGroups].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = .6, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheWindSide_P10 = singleFlyDf['FromTheWindPortEnd_P10_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheWindSide_P10 = [item[0] for item in singleFlyEntranceData_TheWindSide_P10 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheWindSide_P10:\n",
    "                axs[counter+2*numOfGroups].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = .6, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheClosedSide_P10 = singleFlyDf['FromTheClosedEnd_P10_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheClosedSide_P10 = [item[0] for item in singleFlyEntranceData_TheClosedSide_P10 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheClosedSide_P10:\n",
    "                axs[counter+3*numOfGroups].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = .6, color='black')\n",
    "\n",
    "        fontdict = {'fontsize':12}\n",
    "        axs[counter+0].set_title('P01_from Wind End| %s' %(group),fontdict=fontdict)        \n",
    "        axs[counter+0].axhline(meanChoiceZoneBorders_P01[0],color='grey')        \n",
    "        axs[counter+0].axhline(meanChoiceZoneBorders_P01[1],color='grey')\n",
    "        axs[counter+0].axhspan(meanBorder_P01,145,color='red',alpha = 0.3)\n",
    "        axs[counter+0].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "        axs[counter+numOfGroups].set_title('P01_from Closed End| %s' %(group),fontdict=fontdict)\n",
    "        axs[counter+numOfGroups].axhline(meanChoiceZoneBorders_P01[0],color='grey')\n",
    "        axs[counter+numOfGroups].axhline(meanChoiceZoneBorders_P01[1],color='grey') \n",
    "        axs[counter+numOfGroups].axhspan(meanBorder_P01,145,color='red',alpha = 0.3)\n",
    "        axs[counter+numOfGroups].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "        axs[counter+2*numOfGroups].set_title('P10_from Wind End| %s' %(group),fontdict=fontdict)\n",
    "        axs[counter+2*numOfGroups].axhline(meanChoiceZoneBorders_P10[0],color='grey')\n",
    "        axs[counter+2*numOfGroups].axhline(meanChoiceZoneBorders_P10[1],color='grey') \n",
    "        axs[counter+2*numOfGroups].axhspan(0,meanBorder_P10,color='red',alpha = 0.3)\n",
    "        axs[counter+2*numOfGroups].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "        axs[counter+3*numOfGroups].set_title('P10_from Closed End| %s' %(group),fontdict=fontdict)\n",
    "        axs[counter+3*numOfGroups].axhline(meanChoiceZoneBorders_P10[0],color='grey')\n",
    "        axs[counter+3*numOfGroups].axhline(meanChoiceZoneBorders_P10[1],color='grey')\n",
    "        axs[counter+3*numOfGroups].axhspan(0,meanBorder_P10,color='red',alpha = 0.3)\n",
    "        axs[counter+3*numOfGroups].set_ylim(ylim[0],ylim[1])\n",
    "            \n",
    "        #elif mean == True:\n",
    "            \n",
    "            \n",
    "        \n",
    "    elif individualFlies != None:\n",
    "        \n",
    "        counter = 0\n",
    "        numOfflies = individualFlies[1] - individualFlies[0]\n",
    "        for fly in range(individualFlies[0],individualFlies[1]):   \n",
    "            \n",
    "            singleFlyDf = data.iloc[fly]\n",
    "            singleFlyHeadX = singleFlyDf['HeadX(pix)']\n",
    "            genotype = singleFlyDf['Genotype']\n",
    "            flyID = singleFlyDf['Fly ID']\n",
    "            \n",
    "            Border_P01 = singleFlyDf['Border|P01']\n",
    "            Border_P10 = singleFlyDf['Border|P10']\n",
    "            ChoiceZoneBorders_P01 = singleFlyDf['ChoiceZoneBordersperFly_P01']\n",
    "            ChoiceZoneBorders_P10 = singleFlyDf['ChoiceZoneBordersperFly_P10']\n",
    "        \n",
    "            singleFlyEntranceData_TheWindSide_P01 = singleFlyDf['FromTheWindPortEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheWindSide_P01 = [item[0] for item in singleFlyEntranceData_TheWindSide_P01 if item]\n",
    "            \n",
    "            linewidth = 1 + 0.8*(numOfflies-1)\n",
    "            for index in singleFlyEntranceIndexList_TheWindSide_P01:\n",
    "                axs[counter*4+0].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = linewidth, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheClosedSide_P01 = singleFlyDf['FromTheClosedEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheClosedSide_P01 = [item[0] for item in singleFlyEntranceData_TheClosedSide_P01 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheClosedSide_P01:\n",
    "                axs[counter*4+1].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = linewidth, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheWindSide_P10 = singleFlyDf['FromTheWindPortEnd_P10_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheWindSide_P10 = [item[0] for item in singleFlyEntranceData_TheWindSide_P10 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheWindSide_P10:\n",
    "                axs[counter*4+2].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = linewidth, color='black')\n",
    "\n",
    "            singleFlyEntranceData_TheClosedSide_P10 = singleFlyDf['FromTheClosedEnd_P10_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX']\n",
    "            singleFlyEntranceIndexList_TheClosedSide_P10 = [item[0] for item in singleFlyEntranceData_TheClosedSide_P10 if item]\n",
    "\n",
    "            for index in singleFlyEntranceIndexList_TheClosedSide_P10:\n",
    "                axs[counter*4+3].plot(range(durationAfterEntrance_frames), singleFlyHeadX[index:index+durationAfterEntrance_frames], linewidth = linewidth, color='black')\n",
    "\n",
    "            fontdict = {'fontsize':12*(numOfGroups/1.2)}\n",
    "            axs[counter*4+0].set_title('%s, ID: %s|P01_from Wind End' %(genotype,flyID),fontdict=fontdict)        \n",
    "            axs[counter*4+0].axhline(ChoiceZoneBorders_P01[0],color='grey')        \n",
    "            axs[counter*4+0].axhline(ChoiceZoneBorders_P01[1],color='grey')\n",
    "            axs[counter*4+0].axhspan(Border_P01,145,color='red',alpha = 0.3)\n",
    "            axs[counter*4+0].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "            axs[counter*4+1].set_title('P01_from Closed End',fontdict=fontdict)\n",
    "            axs[counter*4+1].axhline(ChoiceZoneBorders_P01[0],color='grey')\n",
    "            axs[counter*4+1].axhline(ChoiceZoneBorders_P01[1],color='grey') \n",
    "            axs[counter*4+1].axhspan(Border_P01,145,color='red',alpha = 0.3)\n",
    "            axs[counter*4+1].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "            axs[counter*4+2].set_title('P10_from Wind End',fontdict=fontdict)\n",
    "            axs[counter*4+2].axhline(ChoiceZoneBorders_P10[0],color='grey')\n",
    "            axs[counter*4+2].axhline(ChoiceZoneBorders_P10[1],color='grey') \n",
    "            axs[counter*4+2].axhspan(0,Border_P10,color='red',alpha = 0.3)\n",
    "            axs[counter*4+2].set_ylim(ylim[0],ylim[1])\n",
    "\n",
    "            axs[counter*4+3].set_title('P10_from Closed End',fontdict=fontdict)\n",
    "            axs[counter*4+3].axhline(ChoiceZoneBorders_P10[0],color='grey')\n",
    "            axs[counter*4+3].axhline(ChoiceZoneBorders_P10[1],color='grey')\n",
    "            axs[counter*4+3].axhspan(0,Border_P10,color='red',alpha = 0.3)\n",
    "            axs[counter*4+3].set_ylim(ylim[0],ylim[1])\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "    return axs\n",
    "\n",
    "def VisualizeTheChoiceZoneTrajectories(df, individualFlies = None, groupBy = None, groupsToPlot = None, durationAfterEntrance_frames=50, \n",
    "                                       mean = False, CI = 95, hspace = .3, wspace = .3, ylim = [30,110]):\n",
    "   \n",
    "    if individualFlies == None:\n",
    "        #if mean == False:\n",
    "        if groupsToPlot == None:    \n",
    "            df_grouped = df.groupby(groupBy)\n",
    "            numOfGroups = len(df_grouped)\n",
    "            figSize = (5*numOfGroups,20)\n",
    "            fig, axs = plt.subplots(4,numOfGroups, figsize=figSize, facecolor='w', edgecolor='k')\n",
    "            fig.subplots_adjust(hspace = hspace, wspace = wspace)\n",
    "            axs = axs.ravel()\n",
    "\n",
    "            counter = 0\n",
    "\n",
    "            ## for each group of flies (i.e, parent vs offspring), I'm going to plot 4 types of decision zone trajectories:\n",
    "            ## P01: entrance from wind AND closed end, P10: entrance from wind AND closed end\n",
    "            for group,data in df_grouped:\n",
    "                axs = VisualizeGroupsOfData(group,data,counter,numOfGroups,axs,individualFlies,durationAfterEntrance_frames,ylim)\n",
    "                counter += 1\n",
    "\n",
    "        else:    \n",
    "            df_grouped = df.groupby(groupBy)\n",
    "            numOfGroups = len(groupsToPlot)\n",
    "            figSize = (5*numOfGroups,20)\n",
    "            fig, axs = plt.subplots(4,numOfGroups, figsize=figSize, facecolor='w', edgecolor='k')\n",
    "            fig.subplots_adjust(hspace = hspace, wspace = wspace)\n",
    "            axs = axs.ravel()  \n",
    "\n",
    "            counter = 0\n",
    "            for group in groupsToPlot:\n",
    "                data = df_grouped.get_group(group)\n",
    "                axs = VisualizeGroupsOfData(group,data,counter,numOfGroups,axs,individualFlies,durationAfterEntrance_frames,ylim)\n",
    "                counter += 1\n",
    "        \n",
    "        #elif mean == True:\n",
    "            \n",
    "            \n",
    "    \n",
    "    elif individualFlies != None:\n",
    "        group = None\n",
    "        counter = None\n",
    "        \n",
    "        numOfGroups = individualFlies[1] - individualFlies[0]\n",
    "        figSize = (12*numOfGroups,4*numOfGroups**2)\n",
    "        fig, axs = plt.subplots(numOfGroups,4, figsize=figSize, facecolor='w', edgecolor='k')\n",
    "        fig.subplots_adjust(hspace = hspace, wspace = wspace)\n",
    "        axs = axs.ravel() \n",
    "        \n",
    "        axs = VisualizeGroupsOfData(group,df,counter,numOfGroups,axs,individualFlies,durationAfterEntrance_frames,ylim)\n",
    "        \n",
    "    sns.set(style=\"ticks\", palette=\"bright\", color_codes=True)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "VisualizeTheChoiceZoneTrajectories(d, individualFlies = [5,6], groupBy = 'Genotype', groupsToPlot = None,\n",
    "                                   durationAfterEntrance_frames = 30, mean=False, CI = 95, hspace = .3,\n",
    "                                   wspace = .3, ylim = [80,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['FromTheClosedEnd_P01_EnterIdx_ExitIdx_EnterHeadX_ExitHeadX'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d['ChoiceZoneBordersperFly_P01'][5]\n",
    "ChoiceZoneBorders_P01 = d['ChoiceZoneBordersperFly_P01'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = d['HeadX(pix)'][5][1045:1075]\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax1 = plt.subplot(111)\n",
    "ax1.axhline(ChoiceZoneBorders_P01[0],color='grey')\n",
    "ax1.axhline(ChoiceZoneBorders_P01[1],color='grey')\n",
    "\n",
    "ax1.plot(range(len(x)), x, color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot any given metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotTheMetric(df,metric,rootDir,mergeIntensities, combineControls,compareLightType, dropNans=False):\n",
    "    df['Sex'] = df['Sex'].apply(lambda x: x.split('-')[0])\n",
    "    df['Satiety'] = df['Satiety'].apply(lambda x: x.split('-')[0])\n",
    "    \n",
    "    ##Combine fed2, starved2 into one dataset\n",
    "    df.loc[df['Satiety'] == 'fed2', 'Satiety'] = 'fed'\n",
    "    df.loc[df['Satiety'] == 'starved2', 'Satiety'] = 'starved'\n",
    "    \n",
    "    ## open new folders to save the results\n",
    "    \n",
    "    newFolderName = rootDir + '/' + metric\n",
    "    if not os.path.exists(newFolderName):\n",
    "        os.makedirs(newFolderName)\n",
    "        \n",
    "    newFolderName = rootDir + '/' + metric + '/P01'\n",
    "    if not os.path.exists(newFolderName):\n",
    "        os.makedirs(newFolderName)\n",
    "        \n",
    "    newFolderName = rootDir + '/' + metric + '/P10'\n",
    "    if not os.path.exists(newFolderName):\n",
    "        os.makedirs(newFolderName)\n",
    "    \n",
    "    newFolderName = rootDir + '/' + metric + '/Mean'\n",
    "    if not os.path.exists(newFolderName):\n",
    "        os.makedirs(newFolderName)\n",
    "    \n",
    "    ## Save the df which contains the quantitative values of the given metrics, in case I need to plot them again\n",
    "    savePath = rootDir + '/' + metric + '/'\n",
    "    df.to_pickle(savePath + metric + '_values.pkl')\n",
    "    \n",
    "    ## define the color palette\n",
    "    if len(df['Genotype'].unique()) == 3:\n",
    "        myPal = {df['Genotype'].unique()[0] : 'lightgreen',\n",
    "                 df['Genotype'].unique()[1] : 'cyan',\n",
    "                 df['Genotype'].unique()[2]:  'red'}\n",
    "        \n",
    "    elif len(df['Genotype'].unique()) == 5:\n",
    "        myPal = {df['Genotype'].unique()[0] : 'lightgreen',\n",
    "                 df['Genotype'].unique()[1] : 'coral',\n",
    "                 df['Genotype'].unique()[2]:  'orchid',\n",
    "                 df['Genotype'].unique()[3] : 'red',\n",
    "                 df['Genotype'].unique()[4]:  'royalblue'}\n",
    "        \n",
    "    ## get the list of vairables    \n",
    "    listofSex = df['Sex'].unique()\n",
    "    listofSatiety = df['Satiety'].unique()\n",
    "    listofWindStat = df['Wind status'].unique()\n",
    "    listofGenotypes = df['Genotype'].unique()\n",
    "    listofLightType = ['Pulse']\n",
    "    \n",
    "    df.loc[df['Light Intensity(uW/mm2)'] == \")70u\",\"Light Intensity(uW/mm2)\"] = \"70uW\"\n",
    "    df.loc[df['Light Intensity(uW/mm2)'] == \")28mV\",\"Light Intensity(uW/mm2)\"] = \"28mV\"\n",
    "    df.loc[df['Light Intensity(uW/mm2)'] == \")14mV\",\"Light Intensity(uW/mm2)\"] = \"14mV\"\n",
    "    df.loc[df['Genotype'] == \"w1118-UAS-Cschrimson\",\"Genotype\"] = \"w1118-UAS-CsChrimson\"\n",
    "    \n",
    "            \n",
    "#     listofIntensities = df['Light Intensity(uW/mm2)'].unique()\n",
    "#     listofIntensities = ['4-65mV','9-3mV','14mV'] # constant\n",
    "#     listofIntensities = ['9-3mV','18-6mV','28mV'] # pulsed\n",
    "    listofIntensities = ['14mV','21mV','28mV']\n",
    "        \n",
    "    if compareLightType == False:\n",
    "    \n",
    "        if mergeIntensities == False:\n",
    "            ## if combineControls is true, then status-based df, else genotype-based.\n",
    "            if combineControls == True:\n",
    "\n",
    "                ## make the columns to classify data points  (status-based in this case)\n",
    "                df = df.assign(Status_Sex_Satiety_Intensity_Wind = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "                     df['Satiety'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "                     df['Wind status'], index = df.index))  \n",
    "\n",
    "                ## going to generate plots for each of the combination of these three condition, i.e, male_fed__NoAir\n",
    "                for sex in listofSex:\n",
    "                    for satietyStat in listofSatiety:\n",
    "                        for windStat in listofWindStat:\n",
    "\n",
    "                            ## I wanted to keep the original metric name to access the columns in the df.\n",
    "                            ## Generating the new variable, metricForFileName, helps me to specify whether the nans were dropped\n",
    "                            ## in the file name.\n",
    "                            if dropNans == False:\n",
    "                                metricForFileName = metric + '_CombinedControls'\n",
    "                            elif dropNans == True:\n",
    "                                metricForFileName = metric + '_CombinedControls_NansDropped'\n",
    "\n",
    "                            try:\n",
    "                                ## P01 of the metric\n",
    "                                fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Intensity_Wind', y = metric+'_P01' ,\n",
    "                                        color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                                      idx = (\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[3]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[3]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[4]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[4]) + '_' + str(windStat))\n",
    "                                                                              ))\n",
    "                                savePath = rootDir + '/' + metric + '/P01/'\n",
    "                                saveFileName = metricForFileName + '_P01_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "\n",
    "                                ## Get the sample size\n",
    "                                list_of_Status_Sex_Satiety_Intensity_Wind = df['Status_Sex_Satiety_Intensity_Wind'].unique()\n",
    "\n",
    "                                ## The unique list of Status includes both wind and no wind, while the plots include either wind or\n",
    "                                ## no wind. So, in each iteration, I select wind or no wind data based on the variable WindStat,\n",
    "                                ## just like the plotting function. \n",
    "                                select_list_of_Status_Sex_Satiety_Intensity_Wind = [i for i in list_of_Status_Sex_Satiety_Intensity_Wind if str('_' + str(windStat)) in i]\n",
    "\n",
    "                                temp_parent_N = []\n",
    "                                temp_offspring_N = []\n",
    "                                temp_parent_STD = []\n",
    "                                temp_offspring_STD = []\n",
    "\n",
    "                                for c in select_list_of_Status_Sex_Satiety_Intensity_Wind:\n",
    "                                    N = len(df[df['Status_Sex_Satiety_Intensity_Wind'] == c][metric+'_P01'])\n",
    "                                    STD = df[df['Status_Sex_Satiety_Intensity_Wind'] == c][metric+'_P01'].std()\n",
    "                                    if 'Parent' in c:\n",
    "                                        temp_parent_N.append(N)\n",
    "                                        temp_parent_STD.append(STD)\n",
    "                                    elif 'Offspring' in c:\n",
    "                                        temp_offspring_N.append(N)\n",
    "                                        temp_offspring_STD.append(STD)\n",
    "\n",
    "                                b['Parent_N'] = temp_parent_N\n",
    "                                b['Offspring_N'] = temp_offspring_N\n",
    "\n",
    "                                b['Parent_SD'] = temp_parent_STD\n",
    "                                b['Offspring_SD'] = temp_offspring_STD\n",
    "\n",
    "                                b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                ## close the figures to save memory\n",
    "                                plt.close(fig)\n",
    "                                plt.clf()\n",
    "\n",
    "                            ## P10 of the metric\n",
    "                                fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Intensity_Wind', y = metric+'_P10' ,\n",
    "                                        color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                                      idx = (\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[3]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[3]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[4]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[4]) + '_' + str(windStat))\n",
    "                                                                              ))\n",
    "                                savePath = rootDir + '/' + metric + '/P10/'\n",
    "                                saveFileName = metricForFileName + '_P10_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "\n",
    "                                ## Get the sample size\n",
    "                                list_of_Status_Sex_Satiety_Intensity_Wind = df['Status_Sex_Satiety_Intensity_Wind'].unique()\n",
    "\n",
    "                                ## The unique list of Status includes both wind and no wind, while the plots include either wind or\n",
    "                                ## no wind. So, in each iteration, I select wind or no wind data based on the variable WindStat,\n",
    "                                ## just like the plotting function. \n",
    "                                select_list_of_Status_Sex_Satiety_Intensity_Wind = [i for i in list_of_Status_Sex_Satiety_Intensity_Wind if str('_' + str(windStat)) in i]\n",
    "                                temp_parent_N = []\n",
    "                                temp_offspring_N = []\n",
    "                                temp_parent_STD = []\n",
    "                                temp_offspring_STD = []\n",
    "\n",
    "                                for c in select_list_of_Status_Sex_Satiety_Intensity_Wind:\n",
    "                                    N = len(df[df['Status_Sex_Satiety_Intensity_Wind'] == c][metric+'_P10'])\n",
    "                                    STD = df[df['Status_Sex_Satiety_Intensity_Wind'] == c][metric+'_P10'].std()\n",
    "                                    if 'Parent' in c:\n",
    "                                        temp_parent_N.append(N)\n",
    "                                        temp_parent_STD.append(STD)\n",
    "                                    elif 'Offspring' in c:\n",
    "                                        temp_offspring_N.append(N)\n",
    "                                        temp_offspring_STD.append(STD)\n",
    "\n",
    "                                b['Parent_N'] = temp_parent_N\n",
    "                                b['Offspring_N'] = temp_offspring_N\n",
    "\n",
    "                                b['Parent_SD'] = temp_parent_STD\n",
    "                                b['Offspring_SD'] = temp_offspring_STD\n",
    "\n",
    "                                b.to_csv(savePath + saveFileName + '.csv')\n",
    "                                plt.close(fig)\n",
    "                                plt.clf()\n",
    "\n",
    "                                ## Mean of the metric\n",
    "                                fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Intensity_Wind', y = metric + '_Mean' ,\n",
    "                                        color_col= 'Genotype', custom_palette = myPal, float_contrast=False,                     \n",
    "                                      idx = (\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[3]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[3]) + '_' + str(windStat)),\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[4]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[4]) + '_' + str(windStat))\n",
    "                                                                              ))\n",
    "                                savePath = rootDir + '/' + metric + '/Mean/'\n",
    "                                saveFileName = metricForFileName + '_Mean_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "\n",
    "                                ## Get the sample size\n",
    "                                list_of_Status_Sex_Satiety_Intensity_Wind = df['Status_Sex_Satiety_Intensity_Wind'].unique()\n",
    "\n",
    "                                ## The unique list of Status includes both wind and no wind, while the plots include either wind or\n",
    "                                ## no wind. So, in each iteration, I select wind or no wind data based on the variable WindStat,\n",
    "                                ## just like the plotting function. \n",
    "                                select_list_of_Status_Sex_Satiety_Intensity_Wind = [i for i in list_of_Status_Sex_Satiety_Intensity_Wind if str('_' + str(windStat)) in i]\n",
    "                                temp_parent_N = []\n",
    "                                temp_offspring_N = []\n",
    "                                temp_parent_STD = []\n",
    "                                temp_offspring_STD = []\n",
    "\n",
    "                                for c in select_list_of_Status_Sex_Satiety_Intensity_Wind:\n",
    "                                    N = len(df[df['Status_Sex_Satiety_Intensity_Wind'] == c][metric+'_Mean'])\n",
    "                                    STD = df[df['Status_Sex_Satiety_Intensity_Wind'] == c][metric+'_Mean'].std()\n",
    "                                    if 'Parent' in c:\n",
    "                                        temp_parent_N.append(N)\n",
    "                                        temp_parent_STD.append(STD)\n",
    "                                    elif 'Offspring' in c:\n",
    "                                        temp_offspring_N.append(N)\n",
    "                                        temp_offspring_STD.append(STD)\n",
    "\n",
    "                                b['Parent_N'] = temp_parent_N\n",
    "                                b['Offspring_N'] = temp_offspring_N\n",
    "\n",
    "                                b['Parent_SD'] = temp_parent_STD\n",
    "                                b['Offspring_SD'] = temp_offspring_STD\n",
    "\n",
    "                                b.to_csv(savePath + saveFileName + '.csv')\n",
    "                                plt.close(fig)\n",
    "                                plt.clf()\n",
    "                            except:\n",
    "                                print \"Not available %s\" % (str(sex) + '_' + str(satietyStat) + '_' + str(windStat))\n",
    "\n",
    "            elif combineControls == False:  \n",
    "\n",
    "                df.loc[df['Light Intensity(uW/mm2)'] == \")70u\" ,\"Light Intensity(uW/mm2)\"] = \"70uW\"\n",
    "\n",
    "                ## generate the columns to callsify the data points, this time genotype-based\n",
    "                df = df.assign(Genotype_Sex_Satiety_Intensity_Wind = pd.Series(df['Genotype'] + '_' + df['Sex'] + '_' +\n",
    "                     df['Satiety'] + '_'  + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "                     df['Wind status'], index = df.index))\n",
    "\n",
    "                ## going to generate plots for each of the combination of these three condition, i.e, male_fed__NoAir\n",
    "                for sex in listofSex:\n",
    "                    for satietyStat in listofSatiety:\n",
    "                        for windStat in listofWindStat:\n",
    "\n",
    "                            ## I wanted to keep the original metric name to access the columns in the df.\n",
    "                            ## Generating the new variable, metricForFileName, helps me to specify whether the nans were dropped\n",
    "                            ## in the file name.\n",
    "                            if dropNans == False:\n",
    "                                metricForFileName = metric\n",
    "                            elif dropNans == True:\n",
    "                                metricForFileName = metric + '_NansDropped'\n",
    "\n",
    "                            if len(listofGenotypes) == 3:\n",
    "                                try:   \n",
    "                                    ## P01 of the metric\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_P01' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat)),\n",
    "\n",
    "                                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat), \n",
    "                                                   str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                   str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat)),\n",
    "\n",
    "                                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat), \n",
    "                                                   str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                   str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat))))\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/P01/'\n",
    "                                    saveFileName = metricForFileName + '_P01_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "\n",
    "                                    ## P10 of the metric\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_P10' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat)),\n",
    "\n",
    "                                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat), \n",
    "                                                   str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                   str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat)),\n",
    "\n",
    "                                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat), \n",
    "                                                   str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                   str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat))))\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/P10/'\n",
    "                                    saveFileName = metricForFileName + '_P10_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "                                    ## Mean of the metric\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_Mean' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat)),\n",
    "\n",
    "                                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat), \n",
    "                                                   str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                   str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat)),\n",
    "\n",
    "                                                  (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat), \n",
    "                                                   str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                   str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat))))\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/Mean/'\n",
    "                                    saveFileName = metricForFileName + '_Mean_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "                                except:\n",
    "                                    print \"Not available %s\" % (str(sex) + '_' + str(satietyStat) + '_' + str(windStat))\n",
    "\n",
    "\n",
    "                            elif len(listofGenotypes) == 5: \n",
    "\n",
    "                                try:   \n",
    "                                    ## P01 of the metric\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_P01' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat))))\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/P01/'\n",
    "                                    saveFileName = metricForFileName + '_P01_14uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_P01' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat))))\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/P01/'\n",
    "                                    saveFileName = metricForFileName + '_P01_42uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_P01' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat))))\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/P01/'\n",
    "                                    saveFileName = metricForFileName + '_P01_70uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "                                    ## P10 of the metric\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_P10' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat))))\n",
    "\n",
    "\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/P10/'\n",
    "                                    saveFileName = metricForFileName + '_P10_14uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_P10' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat))))\n",
    "\n",
    "\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/P10/'\n",
    "                                    saveFileName = metricForFileName + '_P10_42uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_P10' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat))))\n",
    "\n",
    "\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/P10/'\n",
    "                                    saveFileName = metricForFileName + '_P10_70uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "\n",
    "                                    ## Mean of the metric\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_Mean' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_14uW_' + str(windStat))))\n",
    "\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/Mean/'\n",
    "                                    saveFileName = metricForFileName + '_Mean_14uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_Mean' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_42uW_' + str(windStat))))\n",
    "\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/Mean/'\n",
    "                                    saveFileName = metricForFileName + '_Mean_42uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "\n",
    "                                    fig,b = dabest.plot(df, x = 'Genotype_Sex_Satiety_Intensity_Wind', y = metric+'_Mean' ,\n",
    "                                            color_col= 'Genotype', custom_palette = myPal,                      \n",
    "                                          idx = (\n",
    "                                                 (str(listofGenotypes[0]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat), \n",
    "                                                  str(listofGenotypes[1]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[2]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[3]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat),\n",
    "                                                  str(listofGenotypes[4]) + '_' + str(sex) + '_' + str(satietyStat) + '_70uW_' + str(windStat))))\n",
    "\n",
    "\n",
    "                                    savePath = rootDir + '/' + metric + '/Mean/'\n",
    "                                    saveFileName = metricForFileName + '_Mean_70uW_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                    plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                    b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                    ## close the figures to save memory\n",
    "                                    plt.close(fig)\n",
    "                                    plt.clf()\n",
    "                                except:\n",
    "                                    print \"Not available %s\" % (str(sex) + '_' + str(satietyStat) + '_' + str(windStat))\n",
    "\n",
    "        ## When I want to combine the three intensities, going to use below.\n",
    "        \n",
    "        elif mergeIntensities == True:\n",
    "\n",
    "            newFolderName = rootDir + '/' + metric + '/P01' + '/MergedIntensities'\n",
    "            if not os.path.exists(newFolderName):\n",
    "                os.makedirs(newFolderName)\n",
    "\n",
    "            newFolderName = rootDir + '/' + metric + '/P10' + '/MergedIntensities'\n",
    "            if not os.path.exists(newFolderName):\n",
    "                os.makedirs(newFolderName)\n",
    "\n",
    "            newFolderName = rootDir + '/' + metric + '/Mean' + '/MergedIntensities'\n",
    "            if not os.path.exists(newFolderName):\n",
    "                os.makedirs(newFolderName)\n",
    "\n",
    "\n",
    "            df = df.assign(Status_Sex_Satiety_Wind = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "                     df['Satiety'] + '_' + df['Wind status'], index = df.index))   \n",
    "\n",
    "            if combineControls == True:\n",
    "\n",
    "                ## going to generate plots for each of the combination of these three condition, i.e, male_fed__NoAir\n",
    "                for sex in listofSex:\n",
    "                    for satietyStat in listofSatiety:\n",
    "                        for windStat in listofWindStat:\n",
    "\n",
    "                            ## I wanted to keep the original metric name to access the columns in the df.\n",
    "                            ## Generating the new variable, metricForFileName, helps me to specify whether the nans were dropped\n",
    "                            ## in the file name.\n",
    "                            if dropNans == False:\n",
    "                                metricForFileName = metric + '_CombinedControls_MergedIntensities'\n",
    "                            elif dropNans == True:\n",
    "                                metricForFileName = metric + '_CombinedControls_NansDropped_MergedIntensities'\n",
    "\n",
    "                            try:\n",
    "                            ## P01 of the metric\n",
    "                                fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Wind', y = metric+'_P01' ,\n",
    "                                        color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                                      idx = (\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)),\n",
    "                                             )\n",
    "                                                                              )\n",
    "                                savePath = rootDir + '/' + metric + '/P01' + '/MergedIntensities/'\n",
    "                                saveFileName = metricForFileName + '_P01_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                ## close the figures to save memory\n",
    "                                plt.close(fig)\n",
    "                                plt.clf()\n",
    "\n",
    "                                ## P10 of the metric\n",
    "                                fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Wind', y = metric+'_P10' ,\n",
    "                                        color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                                      idx = (\n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat))\n",
    "                                      ))\n",
    "\n",
    "                                savePath = rootDir + '/' + metric + '/P10/' + '/MergedIntensities/'\n",
    "                                saveFileName = metricForFileName + '_P10_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                                plt.close(fig)\n",
    "                                plt.clf()\n",
    "\n",
    "                                ## Mean of the metric\n",
    "                                fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Wind', y = metric+'_Mean' ,\n",
    "                                        color_col= 'Genotype', custom_palette = myPal, float_contrast=False,                     \n",
    "                                      idx = (                                    \n",
    "                                             ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_'+ str(windStat)))\n",
    "                                                                              )\n",
    "                                savePath = rootDir + '/' + metric + '/Mean/' + '/MergedIntensities/'\n",
    "                                saveFileName = metricForFileName + '_Mean_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                                plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                                b.to_csv(savePath + saveFileName + '.csv')\n",
    "                                plt.close(fig)\n",
    "                                plt.clf()\n",
    "\n",
    "                            except:\n",
    "                                print \"Not available %s\" % (str(sex) + '_' + str(satietyStat) + '_' + str(windStat))\n",
    "    \n",
    "    ## This part of the code is to compare CONSTANT vs PULSED Lights\n",
    "    \n",
    "    elif compareLightType == True:\n",
    "    \n",
    "        ## make the columns to classify data points  (light type-based in this case)\n",
    "        df = df.assign(Status_Sex_Satiety_Intensity_Wind_LT = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "             df['Wind status'] + '_' + df['Light Type'], index = df.index))  \n",
    "\n",
    "        ## going to generate plots for each of the combination of these three condition, i.e, male_fed__NoAir\n",
    "        for sex in listofSex:\n",
    "            for satietyStat in listofSatiety:\n",
    "                for windStat in listofWindStat:\n",
    "                    for lightType in listofLightType:\n",
    "\n",
    "                        ## I wanted to keep the original metric name to access the columns in the df.\n",
    "                        ## Generating the new variable, metricForFileName, helps me to specify whether the nans were dropped\n",
    "                        ## in the file name.\n",
    "                        if dropNans == False:\n",
    "                            metricForFileName = metric + '_CombinedControls'\n",
    "                        elif dropNans == True:\n",
    "                            metricForFileName = metric + '_CombinedControls_NansDropped'\n",
    "\n",
    "#                         try:\n",
    "                            ## P01 of the metric\n",
    "                        fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Intensity_Wind_LT', y = metric+'_P01' ,\n",
    "                                color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                              idx = (\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                                                                                             ))\n",
    "                        savePath = rootDir + '/' + metric + '/P01/'\n",
    "                        saveFileName = metricForFileName + '_P01_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat) + '_' + str(lightType)\n",
    "                        plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "\n",
    "                        ## Get the sample size\n",
    "                        list_of_Status_Sex_Satiety_Intensity_Wind_LT = df['Status_Sex_Satiety_Intensity_Wind_LT'].unique()\n",
    "\n",
    "                        ## The unique list of Status includes both wind and no wind, while the plots include either wind or\n",
    "                        ## no wind. So, in each iteration, I select wind or no wind data based on the variable WindStat,\n",
    "                        ## just like the plotting function. \n",
    "                        select_list_of_Status_Sex_Satiety_Intensity_Wind_LT = [i for i in list_of_Status_Sex_Satiety_Intensity_Wind_LT if (any(intensity in i for intensity in listofIntensities) & (str('_' + str(windStat)) in i) & (str('_' + str(lightType)) in i))]\n",
    "\n",
    "                        temp_parent_N = []\n",
    "                        temp_offspring_N = []\n",
    "                        temp_parent_STD = []\n",
    "                        temp_offspring_STD = []\n",
    "\n",
    "                        for c in select_list_of_Status_Sex_Satiety_Intensity_Wind_LT:\n",
    "                            N = len(df[df['Status_Sex_Satiety_Intensity_Wind_LT'] == c][metric+'_P01'])\n",
    "                            STD = df[df['Status_Sex_Satiety_Intensity_Wind_LT'] == c][metric+'_P01'].std()\n",
    "                            if 'Parent' in c:\n",
    "                                temp_parent_N.append(N)\n",
    "                                temp_parent_STD.append(STD)\n",
    "                            elif 'Offspring' in c:\n",
    "                                temp_offspring_N.append(N)\n",
    "                                temp_offspring_STD.append(STD)\n",
    "\n",
    "                        b['Parent_N'] = temp_parent_N\n",
    "                        b['Offspring_N'] = temp_offspring_N\n",
    "\n",
    "                        b['Parent_SD'] = temp_parent_STD\n",
    "                        b['Offspring_SD'] = temp_offspring_STD\n",
    "\n",
    "                        b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                        ## close the figures to save memory\n",
    "                        plt.close(fig)\n",
    "                        plt.clf()\n",
    "\n",
    "                    ## P10 of the metric\n",
    "                        fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Intensity_Wind_LT', y = metric+'_P10' ,\n",
    "                                color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                              idx = (\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                                                      ))\n",
    "                        savePath = rootDir + '/' + metric + '/P10/'\n",
    "                        saveFileName = metricForFileName + '_P10_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat) + '_' + str(lightType)\n",
    "                        plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "\n",
    "                        ## Get the sample size\n",
    "                        list_of_Status_Sex_Satiety_Intensity_Wind_LT = df['Status_Sex_Satiety_Intensity_Wind_LT'].unique()\n",
    "\n",
    "                        ## The unique list of Status includes both wind and no wind, while the plots include either wind or\n",
    "                        ## no wind. So, in each iteration, I select wind or no wind data based on the variable WindStat,\n",
    "                        ## just like the plotting function. \n",
    "                        select_list_of_Status_Sex_Satiety_Intensity_Wind_LT = [i for i in list_of_Status_Sex_Satiety_Intensity_Wind_LT if (any(intensity in i for intensity in listofIntensities) & (str('_' + str(windStat)) in i) & (str('_' + str(lightType)) in i))]\n",
    "\n",
    "                        temp_parent_N = []\n",
    "                        temp_offspring_N = []\n",
    "                        temp_parent_STD = []\n",
    "                        temp_offspring_STD = []\n",
    "\n",
    "                        for c in select_list_of_Status_Sex_Satiety_Intensity_Wind_LT:\n",
    "                            N = len(df[df['Status_Sex_Satiety_Intensity_Wind_LT'] == c][metric+'_P10'])\n",
    "                            STD = df[df['Status_Sex_Satiety_Intensity_Wind_LT'] == c][metric+'_P10'].std()\n",
    "                            if 'Parent' in c:\n",
    "                                temp_parent_N.append(N)\n",
    "                                temp_parent_STD.append(STD)\n",
    "                            elif 'Offspring' in c:\n",
    "                                temp_offspring_N.append(N)\n",
    "                                temp_offspring_STD.append(STD)\n",
    "\n",
    "                        b['Parent_N'] = temp_parent_N\n",
    "                        b['Offspring_N'] = temp_offspring_N\n",
    "\n",
    "                        b['Parent_SD'] = temp_parent_STD\n",
    "                        b['Offspring_SD'] = temp_offspring_STD\n",
    "\n",
    "                        b.to_csv(savePath + saveFileName + '.csv')\n",
    "                        plt.close(fig)\n",
    "                        plt.clf()\n",
    "\n",
    "                        ## Mean of the metric\n",
    "                        fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Intensity_Wind_LT', y = metric + '_Mean' ,\n",
    "                                color_col= 'Genotype', custom_palette = myPal, float_contrast=False,                     \n",
    "                              idx = (\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                     ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat) + '_' + str(lightType), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat) + '_' + str(lightType)),\n",
    "                                                                      ))\n",
    "                        savePath = rootDir + '/' + metric + '/Mean/'\n",
    "                        saveFileName = metricForFileName + '_Mean_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat) + '_' + str(lightType)\n",
    "                        plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "\n",
    "                        ## Get the sample size\n",
    "                        list_of_Status_Sex_Satiety_Intensity_Wind_LT = df['Status_Sex_Satiety_Intensity_Wind_LT'].unique()\n",
    "\n",
    "                        ## The unique list of Status includes both wind and no wind, while the plots include either wind or\n",
    "                        ## no wind. So, in each iteration, I select wind or no wind data based on the variable WindStat,\n",
    "                        ## just like the plotting function. \n",
    "                        select_list_of_Status_Sex_Satiety_Intensity_Wind_LT = [i for i in list_of_Status_Sex_Satiety_Intensity_Wind_LT if (any(intensity in i for intensity in listofIntensities) & (str('_' + str(windStat)) in i) & (str('_' + str(lightType)) in i))]\n",
    "\n",
    "                        temp_parent_N = []\n",
    "                        temp_offspring_N = []\n",
    "                        temp_parent_STD = []\n",
    "                        temp_offspring_STD = []\n",
    "\n",
    "                        for c in select_list_of_Status_Sex_Satiety_Intensity_Wind_LT:\n",
    "                            N = len(df[df['Status_Sex_Satiety_Intensity_Wind_LT'] == c][metric+'_Mean'])\n",
    "                            STD = df[df['Status_Sex_Satiety_Intensity_Wind_LT'] == c][metric+'_Mean'].std()\n",
    "                            if 'Parent' in c:\n",
    "                                temp_parent_N.append(N)\n",
    "                                temp_parent_STD.append(STD)\n",
    "                            elif 'Offspring' in c:\n",
    "                                temp_offspring_N.append(N)\n",
    "                                temp_offspring_STD.append(STD)\n",
    "\n",
    "                        b['Parent_N'] = temp_parent_N\n",
    "                        b['Offspring_N'] = temp_offspring_N\n",
    "\n",
    "                        b['Parent_SD'] = temp_parent_STD\n",
    "                        b['Offspring_SD'] = temp_offspring_STD\n",
    "\n",
    "                        b.to_csv(savePath + saveFileName + '.csv')\n",
    "                        plt.close(fig)\n",
    "                        plt.clf()\n",
    "\n",
    "#                         except:\n",
    "#                             print \"Not available %s\" % (str(sex) + '_' + str(satietyStat) + '_' + str(windStat))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WALiMe(rootDirectory, mergeIntensities=False, pickORN=False,combineControls=True,compareLightType=False):\n",
    "    \n",
    "    if pickORN == False:\n",
    "        ## Get a list of ORNs in the folder\n",
    "        ornList = os.listdir(rootDirectory)\n",
    "\n",
    "        for i in range(len(ornList)):\n",
    "            ## read the data in a df\n",
    "            ORN = ornList[i]\n",
    "            \n",
    "            print '%s is in progress...' %(ORN)\n",
    "\n",
    "            rootDir = os.path.join(rootDirectory,ORN)\n",
    "            fileList = os.listdir(rootDir)\n",
    "\n",
    "            if 'RawDataFrame.pkl' in fileList:\n",
    "                df = pd.read_pickle(rootDir + '/RawDataFrame.pkl')\n",
    "            else:\n",
    "                df = dataToDataframe(rootDir)\n",
    "\n",
    "            ## apply the metrics\n",
    "#             LaXS(df, rootDir, mergeIntensities, combineControls, dropNans=False)\n",
    "#             TSALE(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "            weighted_TSALE(df, rootDir,mergeIntensities,compareLightType, combineControls, dropNans=False)\n",
    "#             LAI(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "\n",
    "#             try:\n",
    "#                 RPI(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "#             except:\n",
    "#                 print \"Did not calculate RPI for some errors in mannwhitney stats for ORN %s\" %(ORN)\n",
    "\n",
    "#             DeltaPercentTimeSpent(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "#             Log2SpeedRatio(df, rootDir, mergeIntensities,combineControls, dropNans=False)\n",
    "#             SpeedCrossingInside(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "#             SpeedCrossingOutside(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "#             NoBC(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "    else:\n",
    "        ORN = pickORN\n",
    "            \n",
    "        print '%s is in progress...' %(ORN)\n",
    "\n",
    "        rootDir = os.path.join(rootDirectory,ORN)\n",
    "        fileList = os.listdir(rootDir)\n",
    "\n",
    "        if 'RawDataFrame.pkl' in fileList:\n",
    "            df = pd.read_pickle(rootDir + '/RawDataFrame.pkl')\n",
    "        else:\n",
    "            df = dataToDataframe(rootDir)\n",
    "\n",
    "        ## apply the metrics\n",
    "#         LaXS(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "#         TSALE(df, rootDir, mergeIntensities,combineControls, dropNans=False)\n",
    "#         print compareLightType\n",
    "        weighted_TSALE(df, rootDir,mergeIntensities,compareLightType, combineControls,dropNans=False)\n",
    "#         LAI(df, rootDir, mergeIntensities,combineControls, dropNans=False)\n",
    "\n",
    "#         try:\n",
    "#             RPI(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "#         except:\n",
    "#             print \"Did not calculate RPI for some errors in mannwhitney stats for ORN %s\" %(ORN)\n",
    "\n",
    "#         DeltaPercentTimeSpent(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "#         Log2SpeedRatio(df, rootDir, mergeIntensities,combineControls, dropNans=False)\n",
    "#         SpeedCrossingInside(df, rootDir, mergeIntensities,combineControls, dropNans=False)\n",
    "#         SpeedCrossingOutside(df, rootDir,mergeIntensities, combineControls, dropNans=False)\n",
    "#         NoBC(df, rootDir, mergeIntensities,combineControls, dropNans=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fed is in progress...\n",
      "Not available male_fileName_NoAir\n",
      "Not available male_fileName_Air\n",
      "Starved is in progress...\n",
      "Not available male_fileName_NoAir\n",
      "Not available male_fileName_Air\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "# %matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "# import bootstrap_contrast as bs\n",
    "from nptdms import *\n",
    "import math\n",
    "from collections import Counter\n",
    "import shutil\n",
    "import progressbar\n",
    "# from svgutils.compose import *\n",
    "import dabest\n",
    "\n",
    "rootDirectory = \"C:/Users/tumkayat/Desktop/ORScreening/TransferToSOD/PulseVConstantLED_ORexperiments/Or92a/\"\n",
    "d = WALiMe(rootDirectory, mergeIntensities=False, pickORN=False, combineControls=True, compareLightType = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"C:/Users/tumkayat/Desktop/ORScreening/TransferToSOD/PulseVConstantLED_ORexperiments/Or92a/Fed/weighted_TSALE/weighted_TSALE_values.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7mV', '14mV', '21mV', '28mV'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Light Intensity(uW/mm2)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " df.loc[df['Light Intensity(uW/mm2)'] == \")28mV\",\"Light Intensity(uW/mm2)\"] = \"28mV\"\n",
    " df.loc[df['Light Intensity(uW/mm2)'] == \")14mV\",\"Light Intensity(uW/mm2)\"] = \"14mV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.assign(Status_Sex_Satiety_Intensity_Wind_LT = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "                 df['Satiety'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "                 df['Wind status'] + '_' + df['Light Type'], index = df.index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Parent_male_fileName_4-65mV_NoAir_Constant',\n",
       "       'Parent_male_fileName_4-65mV_Air_Constant',\n",
       "       'Parent_male_fileName_9-3mV_NoAir_Pulse',\n",
       "       'Parent_male_fileName_9-3mV_Air_Pulse',\n",
       "       'Parent_male_fileName_9-3mV_NoAir_Constant',\n",
       "       'Parent_male_fileName_9-3mV_Air_Constant',\n",
       "       'Parent_male_fileName_18-6mV_NoAir_Pulse',\n",
       "       'Parent_male_fileName_18-6mV_Air_Pulse',\n",
       "       'Parent_male_fileName_14mV_NoAir_Constant',\n",
       "       'Parent_male_fileName_14mV_Air_Constant',\n",
       "       'Parent_male_fileName_28mV_NoAir_Pulse',\n",
       "       'Parent_male_fileName_28mV_Air_Pulse',\n",
       "       'Offspring_male_fileName_4-65mV_NoAir_Constant',\n",
       "       'Offspring_male_fileName_4-65mV_Air_Constant',\n",
       "       'Offspring_male_fileName_9-3mV_NoAir_Pulse',\n",
       "       'Offspring_male_fileName_9-3mV_Air_Pulse',\n",
       "       'Offspring_male_fileName_9-3mV_NoAir_Constant',\n",
       "       'Offspring_male_fileName_9-3mV_Air_Constant',\n",
       "       'Offspring_male_fileName_18-6mV_NoAir_Pulse',\n",
       "       'Offspring_male_fileName_18-6mV_Air_Pulse',\n",
       "       'Offspring_male_fileName_14mV_NoAir_Constant',\n",
       "       'Offspring_male_fileName_14mV_Air_Constant',\n",
       "       'Offspring_male_fileName_28mV_NoAir_Pulse',\n",
       "       'Offspring_male_fileName_28mV_Air_Pulse'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Status_Sex_Satiety_Intensity_Wind_LT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Parent_male_fileName_4-65mV_NoAir_Constant',\n",
       "       'Parent_male_fileName_4-65mV_Air_Constant',\n",
       "       'Parent_male_fileName_9-3mV_NoAir_Pulse',\n",
       "       'Parent_male_fileName_9-3mV_Air_Pulse',\n",
       "       'Parent_male_fileName_9-3mV_NoAir_Constant',\n",
       "       'Parent_male_fileName_9-3mV_Air_Constant',\n",
       "       'Parent_male_fileName_18-6mV_NoAir_Pulse',\n",
       "       'Parent_male_fileName_18-6mV_Air_Pulse',\n",
       "       'Parent_male_fileName_14mV_NoAir_Constant',\n",
       "       'Parent_male_fileName_14mV_Air_Constant',\n",
       "       'Parent_male_fileName_28mV_NoAir_Pulse',\n",
       "       'Parent_male_fileName_28mV_Air_Pulse',\n",
       "       'Offspring_male_fileName_4-65mV_NoAir_Constant',\n",
       "       'Offspring_male_fileName_4-65mV_Air_Constant',\n",
       "       'Offspring_male_fileName_9-3mV_NoAir_Pulse',\n",
       "       'Offspring_male_fileName_9-3mV_Air_Pulse',\n",
       "       'Offspring_male_fileName_9-3mV_NoAir_Constant',\n",
       "       'Offspring_male_fileName_9-3mV_Air_Constant',\n",
       "       'Offspring_male_fileName_18-6mV_NoAir_Pulse',\n",
       "       'Offspring_male_fileName_18-6mV_Air_Pulse',\n",
       "       'Offspring_male_fileName_14mV_NoAir_Constant',\n",
       "       'Offspring_male_fileName_14mV_Air_Constant',\n",
       "       'Offspring_male_fileName_28mV_NoAir_Pulse',\n",
       "       'Offspring_male_fileName_28mV_Air_Pulse'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Status_Sex_Satiety_Intensity_Wind_LT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myPal = {df['Genotype'].unique()[0] : 'lightgreen',\n",
    "                 df['Genotype'].unique()[1] : 'cyan',\n",
    "                 df['Genotype'].unique()[2]:  'red'}\n",
    "sex = 'male'\n",
    "satietyStat = 'fileName'\n",
    "listofIntensities = ['4-65mV','9-3mV','18-6mV','14mV','28mV']\n",
    "windStat = 'NoAir'\n",
    "\n",
    "fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Intensity_Wind', y = 'TSALE' +'_P01' ,\n",
    "                                    color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                                  idx = (\n",
    "                                         ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[0]) + '_' + str(windStat)),\n",
    "                                         ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[1]) + '_' + str(windStat)),\n",
    "                                         ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[2]) + '_' + str(windStat)),\n",
    "                                         ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[3]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[3]) + '_' + str(windStat)),\n",
    "                                         ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[4]) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(listofIntensities[4]) + '_' + str(windStat))\n",
    "                                                                          ))\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b['R'] = [1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove folders: Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rootDir = \"C:/Users/tumkayat/Desktop/ORScreening/All_merged_intensity_wTSALE/\"\n",
    "a = os.listdir(rootDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ORN in a:\n",
    "    ORN_folder = os.path.join(rootDir, ORN)\n",
    "    ORN_content = os.listdir(ORN_folder)\n",
    "    \n",
    "    for i in ORN_content:\n",
    "        if not i[-4:] == \".pkl\":\n",
    "            shutil.rmtree(os.path.join(ORN_folder,i))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove folders: End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"C:/Users/tumkayat/Desktop/ORScreening/TransferToSOD/Orco_activation_R58E02_inhibiton/RawDataFrame.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.assign(Status_Sex_Satiety_Wind = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Wind status'], index = df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.assign(Genotype_Sex_Satiety_Wind = pd.Series(df['Genotype'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Wind status'], index = df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = t.assign(Fly_ID_Genotype_Sex_Satiety_Wind = pd.Series(df['Fly ID'] + '_' + df['Genotype'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Wind status'], index = df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = weighted_TSALE(df, rootDir=\"C:/Users/tumkayat/Desktop/Del\", combineControls=True, dropNans=False, mergeIntensities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and Plot Integrated Intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is by getting the absolute sum of the wTSALE values and contrasting them.\n",
    "\n",
    "def integratedIntensities(df):\n",
    "    \n",
    "    df['Sex'] = df['Sex'].apply(lambda x: x.split('-')[0])\n",
    "    ## assign Fly ID labels to select fly per condition and get 3 intensities \n",
    "    df = df.assign(FlyID_Genotype_Sex_Satiety_Wind = pd.Series(df['Fly ID'] + '_' + df['Genotype'] + '_' + df['Sex'] + '_' +\n",
    "                 df['Satiety'] + '_' + df['Wind status'], index = df.index))\n",
    "\n",
    "    df = df.assign(Status_Sex_Satiety_Wind = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Wind status'], index = df.index))\n",
    "\n",
    "    ## Go thru the fly ID + conditions\n",
    "    unique_fly_list = df['FlyID_Genotype_Sex_Satiety_Wind'].unique()\n",
    "\n",
    "    temp = {'Genotype':[], 'Sex':[], 'Satiety':[], 'Wind status':[], 'Genotype_Sex_Satiety_Wind':[], 'sum_abs_wTSALE_P10':[], 'Status_Sex_Satiety_Wind':[],}\n",
    "\n",
    "    ## Get summed absolute wTSALE_P10 per fly across conditions\n",
    "    ## Write the results to a new table\n",
    "    for i in range(len(unique_fly_list)):\n",
    "        dfOI = df[(df['FlyID_Genotype_Sex_Satiety_Wind'] == df['FlyID_Genotype_Sex_Satiety_Wind'].unique()[i])]\n",
    "        sum_abs_wTSALE_P10 = dfOI['weighted_TSALE_P10'].abs().sum()\n",
    "\n",
    "        temp['sum_abs_wTSALE_P10'].append(sum_abs_wTSALE_P10)\n",
    "        temp['Genotype_Sex_Satiety_Wind'].append(unique_fly_list[i][4:])\n",
    "        temp['Status_Sex_Satiety_Wind'].append(dfOI['Status_Sex_Satiety_Wind'].iloc[0])\n",
    "        temp['Genotype'].append(dfOI['Genotype'].iloc[0])\n",
    "        temp['Sex'].append(dfOI['Sex'].iloc[0])\n",
    "        temp['Satiety'].append(dfOI['Satiety'].iloc[0])\n",
    "        temp['Wind status'].append(dfOI['Wind status'].iloc[0])\n",
    "    \n",
    "    IntegratedIntensity_df = pd.DataFrame.from_dict(temp)\n",
    "\n",
    "    return IntegratedIntensity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def IntegratedintensityPlot(df, rootDir):\n",
    "    ## define the color palette\n",
    "    if len(df['Genotype'].unique()) == 3:\n",
    "        myPal = {df['Genotype'].unique()[0] : 'lightgreen',\n",
    "                 df['Genotype'].unique()[1] : 'cyan',\n",
    "                 df['Genotype'].unique()[2]:  'red'}\n",
    "\n",
    "    listofSex = df['Sex'].unique()\n",
    "    listofSatiety = df['Satiety'].unique()\n",
    "    listofWindStat = df['Wind status'].unique()\n",
    "    listofGenotypes = df['Genotype'].unique()\n",
    "\n",
    "    ## going to generate plots for each of the combination of these three condition, i.e, male_fed__NoAir\n",
    "    for sex in listofSex:\n",
    "        for satietyStat in listofSatiety:\n",
    "            for windStat in listofWindStat:\n",
    "\n",
    "                fig,b = dabest.plot(df, x = 'Status_Sex_Satiety_Wind', y = 'sum_abs_wTSALE_P10' ,\n",
    "                                    color_col= 'Genotype', custom_palette = myPal,  float_contrast=False,                     \n",
    "                                  idx = (\n",
    "                                         ('Parent_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat), 'Offspring_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)))\n",
    "                                                                          )\n",
    "                savePath = rootDir + '/weighted_TSALE/SummedAbsoluteWTSALE/P10/'\n",
    "                if not os.path.exists(savePath):\n",
    "                    os.makedirs(savePath)\n",
    "            \n",
    "                saveFileName = 'DeltaMean_of_SummedAbsWTSALE' + '_P10_' + str(sex) + '_' + str(satietyStat) + '_' + str(windStat)\n",
    "                plt.savefig(savePath + saveFileName + '.svg',dpi=1000,bbox_inches='tight')\n",
    "                b.to_csv(savePath + saveFileName + '.csv')\n",
    "\n",
    "                plt.close(fig)\n",
    "                plt.clf()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Go thru the ORNs to analyse and plot summed abs wTSALE\n",
    "rootDirectory = \"C:/Users/tumkayat/Desktop/ORScreening/All_merged_intensity_wTSALE/\"\n",
    "\n",
    "ornList = os.listdir(rootDirectory)\n",
    "\n",
    "for i in range(len(ornList)):\n",
    "    ## read the data in a df\n",
    "    ORN = ornList[i]\n",
    "\n",
    "    print '%s is in progress...' %(ORN)\n",
    "\n",
    "    rootDir = os.path.join(rootDirectory,ORN)\n",
    "    df = pd.read_pickle(rootDir + '/weighted_TSALE/weighted_TSALE_values.pkl')\n",
    "    \n",
    "    int_df = integratedIntensities(df)\n",
    "    IntegratedintensityPlot(int_df, rootDir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Sex'][df['Sex'] == ('male-asghar')] = 'male-combined'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Status'][df['Genotype'].str.contains('W1118')] = 'Parent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['Light Intensity(uW/mm2)'] == \")70u\" ,\"Light Intensity(uW/mm2)\"] = \"70uW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.assign(Status_Sex_Satiety_Intensity_Wind = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "             df['Wind status'], index = df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(df['Status_Sex_Satiety_Intensity_Wind'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot individual flies across the 12 conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"C:\\\\Users\\\\tumkayat\\\\Google Drive\\\\PhD thesis\\\\Thesis\\\\Figures\\\\Chapter2\\\\DataForTheFigures\\\\Orco_reverse\\\\weighted_TSALE_values.pkl\")\n",
    "\n",
    "df = df.assign(Genotype_Sex_Satiety_Intensity_Wind = pd.Series(df['Genotype'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "             df['Wind status'], index = df.index))\n",
    "\n",
    "df = df.assign(Status_Sex_Satiety_Intensity_Wind = pd.Series(df['Status'] + '_' + df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "             df['Wind status'], index = df.index))\n",
    "\n",
    "df = df.assign(Sex_Satiety_Intensity_Wind = pd.Series(df['Sex'] + '_' +\n",
    "             df['Satiety'] + '_' + df['Light Intensity(uW/mm2)'] + '_' +\n",
    "             df['Wind status'], index = df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Sex_Satiety_Intensity_Wind'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Genotype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Here I get the sibling controls and experiments across 12 conditions\n",
    "Ctrl_df = df[(df['Genotype'] == 'w1118-UAS-CsChrimson') | (df['Genotype'] == 'w1118-Orco-Gal4')]\n",
    "Exp_df = df[(df['Genotype'] == 'Orco-Gal4-UAS-CsChrimson')]\n",
    "\n",
    "condlist = ['Male_Fed_14uW_NoAir', 'Male_Fed_14uW_Air', \n",
    "            'Male_Fed_42uW_NoAir', 'Male_Fed_42uW_Air',  \n",
    "            'Male_Fed_70uW_NoAir', 'Male_Fed_70uW_Air']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getConditionFrame(df, conditionlist):\n",
    "\n",
    "    temp = {}\n",
    "    ## i.e. [v1,v2,..v12] Then gonna send each sublists to plot in a for loop     \n",
    "    \n",
    "    for i in range(len(condlist)): \n",
    "        temp['Step' + str(i) + '_P01'] = []\n",
    "        temp['Step' + str(i) + '_P10'] = [] \n",
    "        temp['Genotype'] = []\n",
    "        \n",
    "        d = df[df['Sex_Satiety_Intensity_Wind'] == condlist[i]]\n",
    "        \n",
    "        for fly in range(d.shape[0]):                   \n",
    "            val_P01 = d['weighted_TSALE_P01'].iloc[fly]\n",
    "            val_P10 = d['weighted_TSALE_P10'].iloc[fly]\n",
    "            \n",
    "            temp['Step' + str(i) + '_P01'].append(val_P01)\n",
    "            temp['Step' + str(i) + '_P10'].append(val_P10)\n",
    "            temp['Genotype'].append(d['Genotype'].iloc[fly])        \n",
    "        \n",
    "    AcrossConditions_df = pd.DataFrame.from_dict(temp)\n",
    "       \n",
    "    AcrossConditions_df['wTSALE_across_conditions'] = AcrossConditions_df[['Step0_P01','Step0_P10','Step1_P01','Step1_P10', \\\n",
    "                            'Step2_P01' , 'Step2_P10' , \\\n",
    "                            'Step3_P01' , 'Step3_P10' , \\\n",
    "                            'Step4_P01' , 'Step4_P10' , \\\n",
    "                            'Step5_P01' , 'Step5_P10']].values.tolist()\n",
    "    return AcrossConditions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ctrl_across_conditions = getConditionFrame(Ctrl_df,condlist)\n",
    "Exp_across_conditions = getConditionFrame(Exp_df,condlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get the \"condition frame\" and use this function to plot\n",
    "def confidenceInterval(data):  # Function calculates data arrays' CI. \n",
    "    n = len(data)\n",
    "    m, std = np.nanmean(data), np.nanstd(data)\n",
    "    moe = 1.96 * std/np.sqrt(n)\n",
    "   \n",
    "    return m-moe, m+moe, n, std\n",
    "\n",
    "def sequentialPlot(df,color=False):\n",
    "    \n",
    "    ## import the libraries, set some parameters\n",
    "    import itertools\n",
    "    from matplotlib.lines import Line2D\n",
    "    import scipy.stats\n",
    "\n",
    "    style='ticks'\n",
    "    context='notebook'\n",
    "    font='Arial'\n",
    "    if color == False:\n",
    "        colorlist = ['green','coral']\n",
    "    else:\n",
    "        colorlist = color\n",
    "    jitter = 0 ## in case want to separate the lines\n",
    "    color_id = 0\n",
    "\n",
    "    ## these are for the legend\n",
    "    custom_lines = [Line2D([0], [0], color = 'k', marker = 'o',lw=1)]\n",
    "    legend_labels = ['Mean [95%CI]']\n",
    "\n",
    "    sns.set(style=style,context =context,font=font)\n",
    "\n",
    "    fig1 = plt.figure(figsize=(10,4))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "\n",
    "    ## then plotting the lines by iterating 12-value-containing sublists from the df\n",
    "    ## grouped by genotypye, especially for controls\n",
    "    for g,d in df.groupby('Genotype'):\n",
    "\n",
    "        for fly in range(len(d)):\n",
    "\n",
    "            values_per_fly = d['wTSALE_across_conditions'].iloc[fly]\n",
    "            x1 = 1    \n",
    "            for i in range(len(values_per_fly)-1):\n",
    "                x2 = x1 + 1 - jitter\n",
    "                y1 = values_per_fly[i]\n",
    "                y2 = values_per_fly[i+1]\n",
    "                ax1.plot([x1,x2],[y1,y2], label = g, color=colorlist[color_id], linewidth=0.3,zorder=0,alpha=.4)\n",
    "\n",
    "                x1 = x1 + 1\n",
    "\n",
    "        custom_lines.append(Line2D([0], [0], color = colorlist[color_id], lw=1))\n",
    "        legend_labels.append(g+' (n=' + str(len(d)) + ')')\n",
    "        color_id = color_id + 1\n",
    "        \n",
    "    ## Get the means and CIs here \n",
    "    means = []\n",
    "    sample_size = []\n",
    "    std = []\n",
    "    ci_lb = []\n",
    "    ci_ub = []\n",
    "            \n",
    "    ## calculating the means and CIs of each condition\n",
    "    across_conditions_matrix = np.array(df['wTSALE_across_conditions'].tolist())\n",
    "    \n",
    "    for i in range(len(across_conditions_matrix[0])):\n",
    "        data = across_conditions_matrix[:,i]\n",
    "        means.append(np.nanmean(data))\n",
    "        CI_LB, CI_UB, N, STD = confidenceInterval(data)\n",
    "        ci_lb.append(CI_LB)\n",
    "        ci_ub.append(CI_UB)\n",
    "        sample_size.append(N)\n",
    "        std.append(STD)\n",
    "\n",
    "    stats_table = {'SummaryES':means, 'Sample_size':sample_size, 'Standart_dev':std, 'CI_LB':ci_lb, 'CI_UB':ci_ub}\n",
    "    ## plotting the mean dots , zorder specifies the layer order - i.e dots are in the front\n",
    "    x1 = 1\n",
    "    for i in range(len(means)):\n",
    "        ax1.scatter(x1, means[i], s=90,c='k',zorder=10)\n",
    "        ax1.plot([x1,x1], [ci_lb[i], ci_ub[i]], color='k', lw=1)\n",
    "        x1 = x1 + 1\n",
    "\n",
    "    ax1.set_ylim(-1,1)\n",
    "    ax1.set_ylabel('delta wTSALE')\n",
    "#     ax1.set_xticks(np.arange(0,len(condlist)*2+1))\n",
    "    xlabel = []\n",
    "#     for c in condlist:\n",
    "#         xlabel.append(c + '_P01')\n",
    "#         xlabel.append(c + '_P10')\n",
    "    ax1.set_xticklabels(xlabel,rotation=45)\n",
    "    ax1.legend(custom_lines, legend_labels,bbox_to_anchor=(1, 1))\n",
    "\n",
    "    sns.despine()\n",
    "    stats_table['Steps'] = xlabel\n",
    "    stats_table_df = pd.DataFrame.from_dict(stats_table)\n",
    "\n",
    "    return fig1, stats_table_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Exp_across_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, s = sequentialPlot(Ctrl_across_conditions, color = False)\n",
    "# fig, s = sequentialPlot(Exp_across_conditions, color = ['royalblue'])\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'Orco_reverse_ctrl'\n",
    "fig.savefig(\"C:\\\\Users\\\\tumkayat\\\\Google Drive\\\\PhD thesis\\\\Thesis\\\\Figures\\\\Chapter2\\\\Orco_reverse\\\\\" + fname + \".pdf\",dpi=1000,bbox_inches='tight')\n",
    "s.to_csv(\"C:\\\\Users\\\\tumkayat\\\\Google Drive\\\\PhD thesis\\\\Thesis\\\\Figures\\\\Chapter2\\\\Orco_reverse\\\\\" + fname + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrast of the means across 12-steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ContrastofSequence(df_ctrl, df_exp):\n",
    "    contrast_means = []\n",
    "    contrast_CI_LB = []\n",
    "    contrast_CI_UB = []\n",
    "    contrast_samplesize = []\n",
    "    contrast_STD = []\n",
    "    \n",
    "    for i in range(len(df_ctrl)):\n",
    "        mean_ctrl = df_ctrl['SummaryES'][i]\n",
    "        mean_exp = df_exp['SummaryES'][i]\n",
    "        \n",
    "        N_ctrl = df_ctrl['Sample_size'][i]\n",
    "        N_exp = df_exp['Sample_size'][i]\n",
    "        \n",
    "        STD_ctrl = df_ctrl['Standart_dev'][i]\n",
    "        STD_exp = df_exp['Standart_dev'][i]\n",
    "        \n",
    "        mean_diff = mean_exp - mean_ctrl\n",
    "        STD_pooled = np.sqrt(((N_ctrl-1) * (STD_ctrl**2) + (N_exp-1)*(STD_exp**2)) / float((N_ctrl+N_exp-2)))\n",
    "        #http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_confidence_intervals/bs704_confidence_intervals5.html\n",
    "        \n",
    "        moe = 1.96 * STD_pooled * np.sqrt((1./N_ctrl)+(1./N_exp))\n",
    "        CI_LB = mean_diff - moe\n",
    "        CI_UB = mean_diff + moe\n",
    "        \n",
    "        contrast_means.append(mean_diff)\n",
    "        contrast_CI_LB.append(CI_LB)\n",
    "        contrast_CI_UB.append(CI_UB)\n",
    "        contrast_samplesize.append((N_ctrl + N_exp)/2.)\n",
    "        contrast_STD.append(STD_pooled)\n",
    "        \n",
    "    ## import the libraries, set some parameters\n",
    "    import itertools\n",
    "    from matplotlib.lines import Line2D\n",
    "    import scipy.stats\n",
    "\n",
    "    style='ticks'\n",
    "    context='notebook'\n",
    "    font='Arial'\n",
    "\n",
    "    sns.set(style=style,context =context,font=font)\n",
    "\n",
    "    fig1 = plt.figure(figsize=(10,4))\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    \n",
    "    ## plotting the mean dots , zorder specifies the layer order - i.e dots are in the front\n",
    "    x1 = 1\n",
    "    for i in range(len(contrast_means)):\n",
    "        ax1.scatter(x1, contrast_means[i], s=90, c='k',zorder=10)\n",
    "        ax1.plot([x1,x1], [contrast_CI_LB[i], contrast_CI_UB[i]], color='k', lw=1)\n",
    "        x1 = x1 + 1\n",
    "\n",
    "    ax1.set_ylim(-1,1)\n",
    "    ax1.set_ylabel('delta-delta wTSALE')\n",
    "#     ax1.set_xticks(np.arange(0,len(condlist)*2+1))\n",
    "    xlabel = []\n",
    "#     for c in condlist:\n",
    "#         xlabel.append(c + '_P01')\n",
    "#         xlabel.append(c + '_P10')\n",
    "    ax1.set_xticklabels(xlabel,rotation=45)\n",
    "#     ax1.legend(custom_lines, legend_labels,bbox_to_anchor=(1, 1))\n",
    "    plt.axhline(color='k', linewidth = '0.5')\n",
    "    sns.despine()\n",
    "    stats_table = {'Steps':xlabel, 'Sample_size':contrast_samplesize,'Standart_dev':contrast_STD, 'SummaryES':contrast_means, 'CI_LB':contrast_CI_LB, 'CI_UB':contrast_CI_UB}\n",
    "#     stats_table_df = pd.DataFrame.from_dict(stats_table)\n",
    "\n",
    "#     return fig1, stats_table_df\n",
    "    return fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_ctrl = pd.read_csv(\"C:\\\\Users\\\\tumkayat\\\\Google Drive\\\\PhD thesis\\\\Thesis\\\\Figures\\\\Chapter2\\\\Orco_forward\\\\Orco_forward_contrast.csv\")\n",
    "# df_exp = pd.read_csv(\"C:\\\\Users\\\\tumkayat\\\\Google Drive\\\\PhD thesis\\\\Thesis\\\\Figures\\\\Chapter2\\\\Orco_reverse\\\\Orco_reverse_contrast.csv\")\n",
    "\n",
    "df_ctrl = pd.read_csv(\"C:\\\\Users\\\\tumkayat\\\\Desktop\\\\WALiAnalyses\\\\OrcoVOrcoRut\\\\ORCO_weighted_TSALE_CombinedControls_P10_male-combined_fed_NoAir.csv\")\n",
    "df_exp = pd.read_csv(\"C:\\\\Users\\\\tumkayat\\\\Desktop\\\\WALiAnalyses\\\\OrcoVOrcoRut\\\\weighted_TSALE_CombinedControls_P10_Fed_NoAir_Constant.csv\")\n",
    "\n",
    "fig, c = ContrastofSequence(df_ctrl, df_exp)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'Orco_forward_v_reverse'\n",
    "fig.savefig(\"C:\\\\Users\\\\tumkayat\\\\Google Drive\\\\PhD thesis\\\\Thesis\\\\Figures\\\\Chapter2\\\\Orco_forward_v_reverse\\\\\" + fname + \".pdf\",dpi=1000,bbox_inches='tight')\n",
    "c.to_csv(\"C:\\\\Users\\\\tumkayat\\\\Google Drive\\\\PhD thesis\\\\Thesis\\\\Figures\\\\Chapter2\\\\Orco_forward_v_reverse\\\\\" + fname + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.close()\n",
    "plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine SVG images of all metrics in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combineSVGImages(rootDirectory,epoch_to_combine):\n",
    "    \n",
    "    for ORN in ornList:\n",
    "        rootDir = os.path.join(rootDirectory,ORN)\n",
    "\n",
    "        ## Page 1\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## LaxS images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LaXS/\" + epoch_to_combine + \"/LaXS_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"A\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LaXS/\" + epoch_to_combine + \"/LaXS_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"B\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LaXS/\" + epoch_to_combine + \"/LaXS_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"C\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LaXS/\" + epoch_to_combine + \"/LaXS_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"D\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21),\n",
    "\n",
    "                ## TSALE images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/TSALE/\" + epoch_to_combine + \"/TSALE_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"E\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/TSALE/\" + epoch_to_combine + \"/TSALE_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"F\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/TSALE/\" + epoch_to_combine + \"/TSALE_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"G\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/TSALE/\" + epoch_to_combine + \"/TSALE_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"H\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p1\" + epoch_to_combine + \".svg\")\n",
    "\n",
    "\n",
    "        ## Page 2\n",
    "\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## weighted TSALE images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/weighted_TSALE/\" + epoch_to_combine + \"/weighted_TSALE_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"I\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/weighted_TSALE/\" + epoch_to_combine + \"/weighted_TSALE_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"J\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/weighted_TSALE/\" + epoch_to_combine + \"/weighted_TSALE_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"K\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/weighted_TSALE/\" + epoch_to_combine + \"/weighted_TSALE_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"L\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21),\n",
    "\n",
    "                ## Light Attraction Index images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LAI/\" + epoch_to_combine + \"/LAI_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"M\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LAI/\" + epoch_to_combine + \"/LAI_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"N\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LAI/\" + epoch_to_combine + \"/LAI_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"O\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/LAI/\" + epoch_to_combine + \"/LAI_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"P\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p2\" + epoch_to_combine + \".svg\")\n",
    "\n",
    "        ## Page 3\n",
    "\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## Reversal PI images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/RPI/\" + epoch_to_combine + \"/RPI_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"R\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/RPI/\" + epoch_to_combine + \"/RPI_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"S\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/RPI/\" + epoch_to_combine + \"/RPI_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"T\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/RPI/\" + epoch_to_combine + \"/RPI_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"U\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21),\n",
    "\n",
    "                ## DeltaPercentTimeSpent images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/DeltaPercentTimeSpent/\" + epoch_to_combine + \"/DeltaPercentTimeSpent_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"V\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/DeltaPercentTimeSpent/\" + epoch_to_combine + \"/DeltaPercentTimeSpent_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"W\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/DeltaPercentTimeSpent/\" + epoch_to_combine + \"/DeltaPercentTimeSpent_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"X\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/DeltaPercentTimeSpent/\" + epoch_to_combine + \"/DeltaPercentTimeSpent_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"Y\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p3\" + epoch_to_combine + \".svg\")\n",
    "\n",
    "        ## Page 4\n",
    "\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## Log2SpeedRatio images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/Log2SpeedRatio/\" + epoch_to_combine + \"/Log2SpeedRatio_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"Z\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/Log2SpeedRatio/\" + epoch_to_combine + \"/Log2SpeedRatio_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"Ai\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/Log2SpeedRatio/\" + epoch_to_combine + \"/Log2SpeedRatio_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"Bi\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/Log2SpeedRatio/\" + epoch_to_combine + \"/Log2SpeedRatio_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"Ci\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21),\n",
    "\n",
    "                ## SpeedCrossingInside images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingInside/\" + epoch_to_combine + \"/SpeedCrossingInside_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"Di\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingInside/\" + epoch_to_combine + \"/SpeedCrossingInside_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"Ei\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingInside/\" + epoch_to_combine + \"/SpeedCrossingInside_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"Fi\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingInside/\" + epoch_to_combine + \"/SpeedCrossingInside_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"Gi\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p4\" + epoch_to_combine + \".svg\")\n",
    "\n",
    "        ## Page 5\n",
    "\n",
    "        Figure(\"59.4cm\", \"84.1cm\", \n",
    "               ## SpeedCrossingOutside images\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingOutside/\" + epoch_to_combine + \"/SpeedCrossingOutside_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"Hi\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingOutside/\" + epoch_to_combine + \"/SpeedCrossingOutside_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"Ii\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 0),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingOutside/\" + epoch_to_combine + \"/SpeedCrossingOutside_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"Ji\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 21),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/SpeedCrossingOutside/\" + epoch_to_combine + \"/SpeedCrossingOutside_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"Ki\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 21),\n",
    "\n",
    "                ## NoBC images\n",
    "\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/NoBC/\" + epoch_to_combine + \"/NoBC_CombinedControls_\" + epoch_to_combine + \"_male_fed_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"Li\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/NoBC/\" + epoch_to_combine + \"/NoBC_CombinedControls_\" + epoch_to_combine + \"_male_fed_Air.svg\").scale(0.025),\n",
    "                  Text(\"Mi\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Fed | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 42),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/NoBC/\" + epoch_to_combine + \"/NoBC_CombinedControls_\" + epoch_to_combine + \"_male_starved_NoAir.svg\").scale(0.025),\n",
    "                  Text(\"Ni\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | No Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(0, 63),\n",
    "            Panel(\n",
    "                  SVG(rootDir + \"/NoBC/\" + epoch_to_combine + \"/NoBC_CombinedControls_\" + epoch_to_combine + \"_male_starved_Air.svg\").scale(0.025),\n",
    "                  Text(\"Oi\", 3, 1, size=1, weight='bold'),\n",
    "                  Text(ORN + \" | Starved | Air\", 13, 1, size=0.5, weight='bold')\n",
    "                 ).move(26.5, 63)).save(rootDir+\"/Metrics_Combined_p5\" + epoch_to_combine + \".svg\")\n",
    "    return None\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootDir = 'C:/Users/tumkayat/Desktop/ORScreening/WALiSAR_all_ORNs/'\n",
    "    \n",
    "combineSVGImages(rootDir,epoch_to_combine = 'P10' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
